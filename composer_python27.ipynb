{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "composer_python27.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatteoTadiello/ProjectDeepLearning/blob/master/composer_python27.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HewwFQYhMHcT",
        "outputId": "9af31545-2f0c-4d5d-cee7-3e94a9112a35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "HOMEBASE = \"gdrive/My\\ Drive/Colab\\ Notebooks/Composer\"\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw1paKpIKngt",
        "colab_type": "code",
        "outputId": "a68bf787-a883-46ef-91dc-e2f363542370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!ls gdrive/My\\ Drive/Colab\\ Notebooks/Composer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu.theanorc   midi.py\t\t   old_train4.py  samples.npy  train.py\n",
            "gpu.theanorc   midi.pyc\t\t   Out\t\t  train2.py    util.py\n",
            "lengths.npy    mt.py\t\t   Presentazione  train3.py    util.pyc\n",
            "live_edit.py   Music\t\t   rand.npy\t  train4.py\n",
            "load_songs.py  NeuralComposer.zip  README.md\t  train5.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxNx1fPcNLe2",
        "colab_type": "code",
        "outputId": "9c93775e-93c9-4da3-da03-0f7fab3a6fb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!python2.7 gdrive/My\\ Drive/Colab\\ Notebooks/Composer/load_songs.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Songs...\n",
            "Saving 0 samples...\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu-6Pw7ZPQfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2000 Epochs\n",
        "!python2.7 gdrive/My\\ Drive/Colab\\ Notebooks/Composer/train4.py gdrive/My\\ Drive/Colab\\ Notebooks/Composer/\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFupWCioN73D",
        "colab_type": "code",
        "outputId": "92dc4a5b-4e88-4b46-dfb9-11c86d6c2887",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69941
        }
      },
      "source": [
        "# 1000 Epochs\n",
        "!python2.7 gdrive/My\\ Drive/Colab\\ Notebooks/Composer/train5.py gdrive/My\\ Drive/Colab\\ Notebooks/Composer/\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Keras...\n",
            "ERROR (theano.gpuarray): pygpu was configured but could not be imported or is too old (version 0.7 or higher required)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/theano/gpuarray/__init__.py\", line 23, in <module>\n",
            "    import pygpu\n",
            "ImportError: No module named pygpu\n",
            "Theano Version: 1.0.4\n",
            "Using Theano backend.\n",
            "Keras Version: 2.2.4\n",
            "Loading Data...\n",
            "Loaded 4092 samples from 186 songs.\n",
            "4092\n",
            "Padding Songs...\n",
            "Building Model...\n",
            "(None, 16, 96, 96)\n",
            "(None, 16, 9216)\n",
            "(None, 16, 2000)\n",
            "(None, 16, 200)\n",
            "(None, 3200)\n",
            "(None, 1600)\n",
            "(None, 120)\n",
            "(None, 1600)\n",
            "(None, 3200)\n",
            "(None, 16, 200)\n",
            "(None, 16, 2000)\n",
            "(None, 16, 9216)\n",
            "(None, 16, 96, 96)\n",
            "Compiling SubModels...\n",
            "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
            "Training...\n",
            "Epoch 0\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.7187\n",
            "Train Loss: 0.718744695186615\n",
            "Saved\n",
            "Means:  [ 0.12665945 -0.25854418  0.05265978 -0.13903767 -0.25854284 -0.04067894]\n",
            "Evals:  [1.11494973 0.40951338 0.28651215 0.25327379 0.23921141 0.22581126]\n",
            "Epoch 1\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 0.1765\n",
            "Train Loss: 0.17647278308868408\n",
            "Epoch 2\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0645\n",
            "Train Loss: 0.0644644945859909\n",
            "Epoch 3\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0760\n",
            "Train Loss: 0.07598733901977539\n",
            "Epoch 4\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0392\n",
            "Train Loss: 0.03924795240163803\n",
            "Epoch 5\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0281\n",
            "Train Loss: 0.02813357673585415\n",
            "Epoch 6\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0228\n",
            "Train Loss: 0.022803939878940582\n",
            "Epoch 7\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 0.0198\n",
            "Train Loss: 0.019750801846385002\n",
            "Epoch 8\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0179\n",
            "Train Loss: 0.017854752019047737\n",
            "Epoch 9\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0164\n",
            "Train Loss: 0.016372768208384514\n",
            "Saved\n",
            "Means:  [ 0.54062104 -0.90917796 -0.6204521   0.70301074 -0.2831266  -0.22071849]\n",
            "Evals:  [7.18708234 2.02408681 1.16794881 1.06393886 0.86720695 0.57483948]\n",
            "Epoch 10\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0152\n",
            "Train Loss: 0.01517073716968298\n",
            "Epoch 11\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0142\n",
            "Train Loss: 0.014183939434587955\n",
            "Epoch 12\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0134\n",
            "Train Loss: 0.013380111195147038\n",
            "Epoch 13\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0127\n",
            "Train Loss: 0.01269745547324419\n",
            "Epoch 14\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0121\n",
            "Train Loss: 0.012102858163416386\n",
            "Epoch 15\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 0.0116\n",
            "Train Loss: 0.01163341011852026\n",
            "Epoch 16\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0112\n",
            "Train Loss: 0.011152266524732113\n",
            "Epoch 17\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0108\n",
            "Train Loss: 0.010754670016467571\n",
            "Epoch 18\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0105\n",
            "Train Loss: 0.010462279431521893\n",
            "Epoch 19\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0102\n",
            "Train Loss: 0.010169452987611294\n",
            "Saved\n",
            "Means:  [ 0.29321194 -0.38553575 -0.19520608  0.2335829  -0.24546151 -0.22147664]\n",
            "Evals:  [8.25521033 2.68096822 1.55258781 1.35719194 1.14612648 0.72786806]\n",
            "Epoch 20\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 75ms/step - loss: 0.0099\n",
            "Train Loss: 0.009896630421280861\n",
            "Epoch 21\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0097\n",
            "Train Loss: 0.009653713554143906\n",
            "Epoch 22\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0095\n",
            "Train Loss: 0.009465173818171024\n",
            "Epoch 23\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0093\n",
            "Train Loss: 0.009304237551987171\n",
            "Epoch 24\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0091\n",
            "Train Loss: 0.00913343857973814\n",
            "Epoch 25\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0090\n",
            "Train Loss: 0.008970366790890694\n",
            "Epoch 26\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0088\n",
            "Train Loss: 0.008782965131103992\n",
            "Epoch 27\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0087\n",
            "Train Loss: 0.008669334463775158\n",
            "Epoch 28\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 0.0085\n",
            "Train Loss: 0.008521816693246365\n",
            "Epoch 29\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0084\n",
            "Train Loss: 0.008397528901696205\n",
            "Saved\n",
            "Means:  [ 0.21355101 -0.17890473 -0.1273011   0.13090733 -0.24305354 -0.07100807]\n",
            "Evals:  [9.01656092 3.34981939 1.82692436 1.56588346 1.36784632 0.85879227]\n",
            "Epoch 30\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0083\n",
            "Train Loss: 0.008297589607536793\n",
            "Epoch 31\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0082\n",
            "Train Loss: 0.008210618980228901\n",
            "Epoch 32\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0081\n",
            "Train Loss: 0.008148878812789917\n",
            "Epoch 33\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0081\n",
            "Train Loss: 0.00806572288274765\n",
            "Epoch 34\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0080\n",
            "Train Loss: 0.007991080172359943\n",
            "Epoch 35\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0079\n",
            "Train Loss: 0.007891615852713585\n",
            "Epoch 36\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0079\n",
            "Train Loss: 0.007856771349906921\n",
            "Epoch 37\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 0.0078\n",
            "Train Loss: 0.007779630832374096\n",
            "Epoch 38\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0077\n",
            "Train Loss: 0.007711838465183973\n",
            "Epoch 39\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0076\n",
            "Train Loss: 0.00764180114492774\n",
            "Saved\n",
            "Means:  [-0.02158602 -0.06034561  0.05493626 -0.05336571 -0.2531696   0.07205667]\n",
            "Evals:  [9.20184788 3.78232777 2.01373699 1.6369262  1.52129047 0.9030556 ]\n",
            "Epoch 40\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0076\n",
            "Train Loss: 0.007592789363116026\n",
            "Epoch 41\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0076\n",
            "Train Loss: 0.007562894374132156\n",
            "Epoch 42\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0076\n",
            "Train Loss: 0.00756695494055748\n",
            "Epoch 43\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0075\n",
            "Train Loss: 0.007514899596571922\n",
            "Epoch 44\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0075\n",
            "Train Loss: 0.007487324066460133\n",
            "Epoch 45\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0075\n",
            "Train Loss: 0.007468101568520069\n",
            "Epoch 46\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0074\n",
            "Train Loss: 0.007424710784107447\n",
            "Epoch 47\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0074\n",
            "Train Loss: 0.00738591980189085\n",
            "Epoch 48\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0073\n",
            "Train Loss: 0.007305954582989216\n",
            "Epoch 49\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0073\n",
            "Train Loss: 0.007277593947947025\n",
            "Saved\n",
            "Means:  [-0.03648224  0.03798407  0.13064203 -0.09244502 -0.3206979   0.03781548]\n",
            "Evals:  [9.14615671 4.11916387 2.14334351 1.72102008 1.62038876 0.94707823]\n",
            "Epoch 50\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0072\n",
            "Train Loss: 0.0072362832725048065\n",
            "Epoch 51\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 0.0072\n",
            "Train Loss: 0.007231139577925205\n",
            "Epoch 52\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0072\n",
            "Train Loss: 0.0071732280775904655\n",
            "Epoch 53\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0071\n",
            "Train Loss: 0.007148591335862875\n",
            "Epoch 54\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0071\n",
            "Train Loss: 0.007113429252058268\n",
            "Epoch 55\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0071\n",
            "Train Loss: 0.007105120457708836\n",
            "Epoch 56\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0070\n",
            "Train Loss: 0.007031313609331846\n",
            "Epoch 57\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 0.0070\n",
            "Train Loss: 0.007040826138108969\n",
            "Epoch 58\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0070\n",
            "Train Loss: 0.006973713170737028\n",
            "Epoch 59\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0070\n",
            "Train Loss: 0.006986068561673164\n",
            "Saved\n",
            "Means:  [-0.06922845  0.15899149  0.55429876 -0.23782295 -0.08449619  0.39912602]\n",
            "Evals:  [9.26565209 4.23435814 2.27860887 2.00014339 1.58975014 0.99793716]\n",
            "Epoch 60\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0069\n",
            "Train Loss: 0.006938257720321417\n",
            "Epoch 61\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0070\n",
            "Train Loss: 0.006952107418328524\n",
            "Epoch 62\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0069\n",
            "Train Loss: 0.006877570878714323\n",
            "Epoch 63\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0069\n",
            "Train Loss: 0.00688813254237175\n",
            "Epoch 64\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0068\n",
            "Train Loss: 0.006813577841967344\n",
            "Epoch 65\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 0.0068\n",
            "Train Loss: 0.006788492668420076\n",
            "Epoch 66\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0067\n",
            "Train Loss: 0.0067076291888952255\n",
            "Epoch 67\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 78ms/step - loss: 0.0067\n",
            "Train Loss: 0.006722378544509411\n",
            "Epoch 68\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0066\n",
            "Train Loss: 0.006644516251981258\n",
            "Epoch 69\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0066\n",
            "Train Loss: 0.006614002399146557\n",
            "Saved\n",
            "Means:  [ 0.18583845  0.02625518  0.2929811  -0.31095916  0.6989651  -0.4122759 ]\n",
            "Evals:  [9.29429079 4.94685921 2.80321478 2.22853387 1.60618787 0.9845548 ]\n",
            "Epoch 70\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 76ms/step - loss: 0.0066\n",
            "Train Loss: 0.006569885648787022\n",
            "Epoch 71\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0066\n",
            "Train Loss: 0.006592212710529566\n",
            "Epoch 72\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0066\n",
            "Train Loss: 0.006576575804501772\n",
            "Epoch 73\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0066\n",
            "Train Loss: 0.00656279968097806\n",
            "Epoch 74\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0065\n",
            "Train Loss: 0.006501834373921156\n",
            "Epoch 75\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0064\n",
            "Train Loss: 0.006436371244490147\n",
            "Epoch 76\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0064\n",
            "Train Loss: 0.0063879708759486675\n",
            "Epoch 77\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 78ms/step - loss: 0.0064\n",
            "Train Loss: 0.006381392944604158\n",
            "Epoch 78\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0063\n",
            "Train Loss: 0.006327805109322071\n",
            "Epoch 79\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 83ms/step - loss: 0.0063\n",
            "Train Loss: 0.006318504456430674\n",
            "Saved\n",
            "Means:  [ 0.1466254  -0.12952384  1.2811804  -0.77024704  0.8486339  -0.38189107]\n",
            "Evals:  [9.11145909 5.45234946 4.06193586 2.6361683  1.8541342  1.25504839]\n",
            "Epoch 80\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0062\n",
            "Train Loss: 0.0062038288451731205\n",
            "Epoch 81\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0062\n",
            "Train Loss: 0.006212130654603243\n",
            "Epoch 82\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0061\n",
            "Train Loss: 0.006075288634747267\n",
            "Epoch 83\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0061\n",
            "Train Loss: 0.006088088732212782\n",
            "Epoch 84\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0060\n",
            "Train Loss: 0.006004956550896168\n",
            "Epoch 85\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0061\n",
            "Train Loss: 0.00612935796380043\n",
            "Epoch 86\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0060\n",
            "Train Loss: 0.0059617990627884865\n",
            "Epoch 87\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0060\n",
            "Train Loss: 0.006006615702062845\n",
            "Epoch 88\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0059\n",
            "Train Loss: 0.005944907199591398\n",
            "Epoch 89\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0059\n",
            "Train Loss: 0.005919875111430883\n",
            "Saved\n",
            "Means:  [ 0.7008648  -0.5715166  -0.40734354 -0.18343954  0.8698764   0.2536106 ]\n",
            "Evals:  [10.19662025  5.26668343  4.46683192  3.23278685  2.65795354  1.66155603]\n",
            "Epoch 90\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 75ms/step - loss: 0.0058\n",
            "Train Loss: 0.005767937749624252\n",
            "Epoch 91\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0057\n",
            "Train Loss: 0.005715034902095795\n",
            "Epoch 92\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0057\n",
            "Train Loss: 0.005727073177695274\n",
            "Epoch 93\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0058\n",
            "Train Loss: 0.005759202875196934\n",
            "Epoch 94\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0057\n",
            "Train Loss: 0.00573518592864275\n",
            "Epoch 95\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0056\n",
            "Train Loss: 0.0056246197782456875\n",
            "Epoch 96\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0056\n",
            "Train Loss: 0.005599038675427437\n",
            "Epoch 97\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0055\n",
            "Train Loss: 0.0054946234449744225\n",
            "Epoch 98\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0054\n",
            "Train Loss: 0.005412504076957703\n",
            "Epoch 99\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0054\n",
            "Train Loss: 0.005393767263740301\n",
            "Saved\n",
            "Means:  [ 0.3114109  -0.16881773 -0.38821805 -0.2318028  -0.28764364  0.00049882]\n",
            "Evals:  [9.14226265 5.0002738  4.07480814 3.85660409 3.19071449 2.13883683]\n",
            "Epoch 100\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0054\n",
            "Train Loss: 0.005413779057562351\n",
            "Epoch 101\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0054\n",
            "Train Loss: 0.005424373783171177\n",
            "Epoch 102\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0054\n",
            "Train Loss: 0.005443403962999582\n",
            "Epoch 103\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0054\n",
            "Train Loss: 0.005389021709561348\n",
            "Epoch 104\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0053\n",
            "Train Loss: 0.005269203335046768\n",
            "Epoch 105\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0052\n",
            "Train Loss: 0.005206025671213865\n",
            "Epoch 106\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0051\n",
            "Train Loss: 0.005115989595651627\n",
            "Epoch 107\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 0.0051\n",
            "Train Loss: 0.005066419020295143\n",
            "Epoch 108\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0050\n",
            "Train Loss: 0.005028054118156433\n",
            "Epoch 109\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0050\n",
            "Train Loss: 0.005038929171860218\n",
            "Epoch 110\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0050\n",
            "Train Loss: 0.004973195027559996\n",
            "Epoch 111\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0050\n",
            "Train Loss: 0.005006834864616394\n",
            "Epoch 112\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0049\n",
            "Train Loss: 0.004899751860648394\n",
            "Epoch 113\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0050\n",
            "Train Loss: 0.004958583042025566\n",
            "Epoch 114\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0049\n",
            "Train Loss: 0.00485607422888279\n",
            "Epoch 115\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0049\n",
            "Train Loss: 0.004917046520859003\n",
            "Epoch 116\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0048\n",
            "Train Loss: 0.0048110466450452805\n",
            "Epoch 117\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0049\n",
            "Train Loss: 0.004867646377533674\n",
            "Epoch 118\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0049\n",
            "Train Loss: 0.004853942897170782\n",
            "Epoch 119\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0049\n",
            "Train Loss: 0.004879341460764408\n",
            "Saved\n",
            "Means:  [ 0.04606963 -0.22621146 -0.2686178  -0.5897305  -0.23524885  0.077879  ]\n",
            "Evals:  [7.7431102  5.72476091 4.97350719 4.4408234  3.56405666 2.83940423]\n",
            "Epoch 120\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0047\n",
            "Train Loss: 0.004683572333306074\n",
            "Epoch 121\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0046\n",
            "Train Loss: 0.004596862941980362\n",
            "Epoch 122\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0045\n",
            "Train Loss: 0.004514141008257866\n",
            "Epoch 123\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0045\n",
            "Train Loss: 0.0044653224758803844\n",
            "Epoch 124\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0045\n",
            "Train Loss: 0.004454304929822683\n",
            "Epoch 125\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 87ms/step - loss: 0.0044\n",
            "Train Loss: 0.0044168694876134396\n",
            "Epoch 126\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0045\n",
            "Train Loss: 0.004495405592024326\n",
            "Epoch 127\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0045\n",
            "Train Loss: 0.004483488388359547\n",
            "Epoch 128\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0046\n",
            "Train Loss: 0.004569931887090206\n",
            "Epoch 129\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0045\n",
            "Train Loss: 0.004520648159086704\n",
            "Epoch 130\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0045\n",
            "Train Loss: 0.004530498292297125\n",
            "Epoch 131\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0045\n",
            "Train Loss: 0.004503321833908558\n",
            "Epoch 132\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0045\n",
            "Train Loss: 0.004514130763709545\n",
            "Epoch 133\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0045\n",
            "Train Loss: 0.004532105289399624\n",
            "Epoch 134\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0044\n",
            "Train Loss: 0.004444620106369257\n",
            "Epoch 135\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 88ms/step - loss: 0.0043\n",
            "Train Loss: 0.004343453329056501\n",
            "Epoch 136\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0043\n",
            "Train Loss: 0.004294357728213072\n",
            "Epoch 137\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0043\n",
            "Train Loss: 0.004267273936420679\n",
            "Epoch 138\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0043\n",
            "Train Loss: 0.004278441425412893\n",
            "Epoch 139\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0043\n",
            "Train Loss: 0.0042639621533453465\n",
            "Saved\n",
            "Means:  [ 0.17582622 -0.08731253 -0.08574867  0.10953747 -0.20685942  0.01259358]\n",
            "Evals:  [7.06317349 4.82298064 4.53455083 4.41193762 3.45558791 3.2168805 ]\n",
            "Epoch 140\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 13s 71ms/step - loss: 0.0043\n",
            "Train Loss: 0.0042880563996732235\n",
            "Epoch 141\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0042\n",
            "Train Loss: 0.00424894830211997\n",
            "Epoch 142\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0042\n",
            "Train Loss: 0.004208170343190432\n",
            "Epoch 143\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0042\n",
            "Train Loss: 0.004170440603047609\n",
            "Epoch 144\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0042\n",
            "Train Loss: 0.0041580237448215485\n",
            "Epoch 145\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0042\n",
            "Train Loss: 0.004208326805382967\n",
            "Epoch 146\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0042\n",
            "Train Loss: 0.004217544104903936\n",
            "Epoch 147\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0042\n",
            "Train Loss: 0.0042188470251858234\n",
            "Epoch 148\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0041\n",
            "Train Loss: 0.004078020341694355\n",
            "Epoch 149\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0040\n",
            "Train Loss: 0.003981702495366335\n",
            "Epoch 150\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0039\n",
            "Train Loss: 0.003947851713746786\n",
            "Epoch 151\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0040\n",
            "Train Loss: 0.003961795009672642\n",
            "Epoch 152\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0040\n",
            "Train Loss: 0.0040229023434221745\n",
            "Epoch 153\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0041\n",
            "Train Loss: 0.00407961243763566\n",
            "Epoch 154\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 0.0040\n",
            "Train Loss: 0.004026459529995918\n",
            "Epoch 155\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0040\n",
            "Train Loss: 0.003970842808485031\n",
            "Epoch 156\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0039\n",
            "Train Loss: 0.003915268462151289\n",
            "Epoch 157\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0039\n",
            "Train Loss: 0.00389148760586977\n",
            "Epoch 158\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0039\n",
            "Train Loss: 0.0038824453949928284\n",
            "Epoch 159\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0039\n",
            "Train Loss: 0.003860894124954939\n",
            "Saved\n",
            "Means:  [ 0.19544126 -0.03682978  0.26623568  0.02373397  0.21904089  0.07433034]\n",
            "Evals:  [6.56644626 4.38132646 4.2735879  4.08373783 3.41617272 3.33465239]\n",
            "Epoch 160\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 76ms/step - loss: 0.0038\n",
            "Train Loss: 0.003814317286014557\n",
            "Epoch 161\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0038\n",
            "Train Loss: 0.0037642677780240774\n",
            "Epoch 162\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0037\n",
            "Train Loss: 0.0037096228916198015\n",
            "Epoch 163\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0037\n",
            "Train Loss: 0.0037338121328502893\n",
            "Epoch 164\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0037\n",
            "Train Loss: 0.003702780930325389\n",
            "Epoch 165\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0037\n",
            "Train Loss: 0.0037307608872652054\n",
            "Epoch 166\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0037\n",
            "Train Loss: 0.003695189952850342\n",
            "Epoch 167\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0037\n",
            "Train Loss: 0.003698635147884488\n",
            "Epoch 168\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0036\n",
            "Train Loss: 0.0036411730106920004\n",
            "Epoch 169\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0036\n",
            "Train Loss: 0.003625740297138691\n",
            "Epoch 170\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 78ms/step - loss: 0.0036\n",
            "Train Loss: 0.0036104528699070215\n",
            "Epoch 171\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0036\n",
            "Train Loss: 0.003639439819380641\n",
            "Epoch 172\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0036\n",
            "Train Loss: 0.003632541047409177\n",
            "Epoch 173\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0036\n",
            "Train Loss: 0.003621578449383378\n",
            "Epoch 174\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 0.0036\n",
            "Train Loss: 0.003600727766752243\n",
            "Epoch 175\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0036\n",
            "Train Loss: 0.003568947082385421\n",
            "Epoch 176\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0036\n",
            "Train Loss: 0.003566158702597022\n",
            "Epoch 177\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0035\n",
            "Train Loss: 0.0035410933196544647\n",
            "Epoch 178\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0035\n",
            "Train Loss: 0.0035401014611124992\n",
            "Epoch 179\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0036\n",
            "Train Loss: 0.0035538619849830866\n",
            "Saved\n",
            "Means:  [-0.03808269 -0.03246187  0.08091829 -0.24410129 -0.13819723 -0.15376624]\n",
            "Evals:  [6.34464255 4.10977718 4.00591176 3.87396624 3.67327725 3.43554549]\n",
            "Epoch 180\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 75ms/step - loss: 0.0036\n",
            "Train Loss: 0.0035512142349034548\n",
            "Epoch 181\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0035\n",
            "Train Loss: 0.0035219916608184576\n",
            "Epoch 182\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 0.0035\n",
            "Train Loss: 0.003479758510366082\n",
            "Epoch 183\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0034\n",
            "Train Loss: 0.003449674928560853\n",
            "Epoch 184\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0034\n",
            "Train Loss: 0.003442109329625964\n",
            "Epoch 185\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0034\n",
            "Train Loss: 0.003449005074799061\n",
            "Epoch 186\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0034\n",
            "Train Loss: 0.0034496427979320288\n",
            "Epoch 187\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0034\n",
            "Train Loss: 0.003400808433070779\n",
            "Epoch 188\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 0.0033\n",
            "Train Loss: 0.0033219363540410995\n",
            "Epoch 189\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0033\n",
            "Train Loss: 0.003282723482698202\n",
            "Epoch 190\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0033\n",
            "Train Loss: 0.003288368694484234\n",
            "Epoch 191\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0034\n",
            "Train Loss: 0.003355134278535843\n",
            "Epoch 192\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0035\n",
            "Train Loss: 0.0034728485625237226\n",
            "Epoch 193\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0035\n",
            "Train Loss: 0.003503468120470643\n",
            "Epoch 194\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0034\n",
            "Train Loss: 0.0033757779747247696\n",
            "Epoch 195\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0033\n",
            "Train Loss: 0.0032696279231458902\n",
            "Epoch 196\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0032\n",
            "Train Loss: 0.0032044604886323214\n",
            "Epoch 197\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0032\n",
            "Train Loss: 0.0032270753290504217\n",
            "Epoch 198\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0032\n",
            "Train Loss: 0.0032169173937290907\n",
            "Epoch 199\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0032\n",
            "Train Loss: 0.0032342993654310703\n",
            "Saved\n",
            "Means:  [ 0.19494289 -0.04943971  0.14082372  0.02420191  0.16308148  0.07969664]\n",
            "Evals:  [6.27832495 4.03733499 3.9545976  3.71069054 3.56150529 3.30575745]\n",
            "Epoch 200\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0032\n",
            "Train Loss: 0.0032001889776438475\n",
            "Epoch 201\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0032\n",
            "Train Loss: 0.003192553296685219\n",
            "Epoch 202\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0031\n",
            "Train Loss: 0.003149615600705147\n",
            "Epoch 203\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0031\n",
            "Train Loss: 0.003126042429357767\n",
            "Epoch 204\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0031\n",
            "Train Loss: 0.003079778514802456\n",
            "Epoch 205\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0031\n",
            "Train Loss: 0.0030822448898106813\n",
            "Epoch 206\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0031\n",
            "Train Loss: 0.0030730876605957747\n",
            "Epoch 207\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0031\n",
            "Train Loss: 0.0030733926687389612\n",
            "Epoch 208\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0031\n",
            "Train Loss: 0.0030909774359315634\n",
            "Epoch 209\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0031\n",
            "Train Loss: 0.003117124317213893\n",
            "Epoch 210\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0032\n",
            "Train Loss: 0.003150190692394972\n",
            "Epoch 211\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0031\n",
            "Train Loss: 0.003117315238341689\n",
            "Epoch 212\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0031\n",
            "Train Loss: 0.0030737286433577538\n",
            "Epoch 213\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0030\n",
            "Train Loss: 0.0030399367678910494\n",
            "Epoch 214\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0031\n",
            "Train Loss: 0.0030632782727479935\n",
            "Epoch 215\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0031\n",
            "Train Loss: 0.00308997998945415\n",
            "Epoch 216\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0031\n",
            "Train Loss: 0.0031052178237587214\n",
            "Epoch 217\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0031\n",
            "Train Loss: 0.0030629029497504234\n",
            "Epoch 218\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 87ms/step - loss: 0.0030\n",
            "Train Loss: 0.0029931431636214256\n",
            "Epoch 219\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0030\n",
            "Train Loss: 0.002961296122521162\n",
            "Epoch 220\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0030\n",
            "Train Loss: 0.0029809209518134594\n",
            "Epoch 221\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0030\n",
            "Train Loss: 0.002981719793751836\n",
            "Epoch 222\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0030\n",
            "Train Loss: 0.002989824628457427\n",
            "Epoch 223\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0030\n",
            "Train Loss: 0.0029744242783635855\n",
            "Epoch 224\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 0.0030\n",
            "Train Loss: 0.0029575747903436422\n",
            "Epoch 225\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0029\n",
            "Train Loss: 0.002947208471596241\n",
            "Epoch 226\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0029\n",
            "Train Loss: 0.0029261833988130093\n",
            "Epoch 227\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0029\n",
            "Train Loss: 0.0028970218263566494\n",
            "Epoch 228\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0029\n",
            "Train Loss: 0.0028910483233630657\n",
            "Epoch 229\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0029\n",
            "Train Loss: 0.0028836207929998636\n",
            "Epoch 230\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 87ms/step - loss: 0.0029\n",
            "Train Loss: 0.002888378920033574\n",
            "Epoch 231\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0029\n",
            "Train Loss: 0.0028703510761260986\n",
            "Epoch 232\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0029\n",
            "Train Loss: 0.0028682153206318617\n",
            "Epoch 233\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0029\n",
            "Train Loss: 0.002867260714992881\n",
            "Epoch 234\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0029\n",
            "Train Loss: 0.0029098147060722113\n",
            "Epoch 235\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0029\n",
            "Train Loss: 0.002928483532741666\n",
            "Epoch 236\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0029\n",
            "Train Loss: 0.0028977717738598585\n",
            "Epoch 237\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0028\n",
            "Train Loss: 0.002839743159711361\n",
            "Epoch 238\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0028\n",
            "Train Loss: 0.0027826232835650444\n",
            "Epoch 239\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 0.0028\n",
            "Train Loss: 0.0027554372791200876\n",
            "Epoch 240\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0027\n",
            "Train Loss: 0.002738849725574255\n",
            "Epoch 241\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0027\n",
            "Train Loss: 0.002740117721259594\n",
            "Epoch 242\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0027\n",
            "Train Loss: 0.002733367495238781\n",
            "Epoch 243\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0028\n",
            "Train Loss: 0.0027696636971086264\n",
            "Epoch 244\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0028\n",
            "Train Loss: 0.002772925654426217\n",
            "Epoch 245\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0028\n",
            "Train Loss: 0.0027929197531193495\n",
            "Epoch 246\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0028\n",
            "Train Loss: 0.0027765838894993067\n",
            "Epoch 247\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0027\n",
            "Train Loss: 0.0027432560455054045\n",
            "Epoch 248\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0027\n",
            "Train Loss: 0.0027350950986146927\n",
            "Epoch 249\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0027\n",
            "Train Loss: 0.0027349668089300394\n",
            "Saved\n",
            "Means:  [-0.05532131  0.01952437 -0.13575266 -0.11809772 -0.13447385 -0.13962874]\n",
            "Evals:  [5.78032667 3.94371268 3.90166097 3.59346783 3.44852934 3.31663745]\n",
            "Epoch 250\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 74ms/step - loss: 0.0027\n",
            "Train Loss: 0.0027297392953187227\n",
            "Epoch 251\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0027\n",
            "Train Loss: 0.002717615570873022\n",
            "Epoch 252\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0027\n",
            "Train Loss: 0.0027157405856996775\n",
            "Epoch 253\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 0.0027\n",
            "Train Loss: 0.0026795275043696165\n",
            "Epoch 254\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0027\n",
            "Train Loss: 0.0026685523334890604\n",
            "Epoch 255\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0027\n",
            "Train Loss: 0.002663436345756054\n",
            "Epoch 256\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0027\n",
            "Train Loss: 0.002653507050126791\n",
            "Epoch 257\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0026\n",
            "Train Loss: 0.002638676669448614\n",
            "Epoch 258\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0026\n",
            "Train Loss: 0.002619741717353463\n",
            "Epoch 259\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0026\n",
            "Train Loss: 0.002601524582132697\n",
            "Epoch 260\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 78ms/step - loss: 0.0026\n",
            "Train Loss: 0.0025859654415398836\n",
            "Epoch 261\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 78ms/step - loss: 0.0026\n",
            "Train Loss: 0.0025929962284862995\n",
            "Epoch 262\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0026\n",
            "Train Loss: 0.0026137724053114653\n",
            "Epoch 263\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0026\n",
            "Train Loss: 0.0026244332548230886\n",
            "Epoch 264\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0026\n",
            "Train Loss: 0.00262233754619956\n",
            "Epoch 265\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 77ms/step - loss: 0.0026\n",
            "Train Loss: 0.0026391244027763605\n",
            "Epoch 266\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 77ms/step - loss: 0.0026\n",
            "Train Loss: 0.0026165253948420286\n",
            "Epoch 267\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 78ms/step - loss: 0.0026\n",
            "Train Loss: 0.0026114003267139196\n",
            "Epoch 268\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 78ms/step - loss: 0.0026\n",
            "Train Loss: 0.0025839346926659346\n",
            "Epoch 269\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 17s 89ms/step - loss: 0.0026\n",
            "Train Loss: 0.002556243445724249\n",
            "Epoch 270\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0025\n",
            "Train Loss: 0.0025473511777818203\n",
            "Epoch 271\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0025\n",
            "Train Loss: 0.0025346591137349606\n",
            "Epoch 272\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0025\n",
            "Train Loss: 0.002541930414736271\n",
            "Epoch 273\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0025\n",
            "Train Loss: 0.002535381121560931\n",
            "Epoch 274\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0025\n",
            "Train Loss: 0.0025330332573503256\n",
            "Epoch 275\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 83ms/step - loss: 0.0025\n",
            "Train Loss: 0.0025229898747056723\n",
            "Epoch 276\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0025\n",
            "Train Loss: 0.002501370385289192\n",
            "Epoch 277\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0025\n",
            "Train Loss: 0.002506356220692396\n",
            "Epoch 278\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 77ms/step - loss: 0.0025\n",
            "Train Loss: 0.002492475789040327\n",
            "Epoch 279\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 78ms/step - loss: 0.0025\n",
            "Train Loss: 0.002497501205652952\n",
            "Epoch 280\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0025\n",
            "Train Loss: 0.0024778505321592093\n",
            "Epoch 281\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0025\n",
            "Train Loss: 0.002460250398144126\n",
            "Epoch 282\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 78ms/step - loss: 0.0024\n",
            "Train Loss: 0.0024243989028036594\n",
            "Epoch 283\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0024\n",
            "Train Loss: 0.002416867995634675\n",
            "Epoch 284\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 78ms/step - loss: 0.0024\n",
            "Train Loss: 0.0024084390606731176\n",
            "Epoch 285\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0024\n",
            "Train Loss: 0.0024028285406529903\n",
            "Epoch 286\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0024\n",
            "Train Loss: 0.0024043808225542307\n",
            "Epoch 287\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 77ms/step - loss: 0.0024\n",
            "Train Loss: 0.002422553952783346\n",
            "Epoch 288\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 77ms/step - loss: 0.0024\n",
            "Train Loss: 0.00244991946965456\n",
            "Epoch 289\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0025\n",
            "Train Loss: 0.002480575582012534\n",
            "Epoch 290\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0025\n",
            "Train Loss: 0.002490515587851405\n",
            "Epoch 291\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 0.0025\n",
            "Train Loss: 0.0024631379637867212\n",
            "Epoch 292\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 78ms/step - loss: 0.0024\n",
            "Train Loss: 0.002405257197096944\n",
            "Epoch 293\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 78ms/step - loss: 0.0024\n",
            "Train Loss: 0.002367512322962284\n",
            "Epoch 294\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 77ms/step - loss: 0.0024\n",
            "Train Loss: 0.0023518644738942385\n",
            "Epoch 295\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 78ms/step - loss: 0.0023\n",
            "Train Loss: 0.002347141969949007\n",
            "Epoch 296\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0023\n",
            "Train Loss: 0.002339010825380683\n",
            "Epoch 297\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0023\n",
            "Train Loss: 0.002348094480112195\n",
            "Epoch 298\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0023\n",
            "Train Loss: 0.002334170276299119\n",
            "Epoch 299\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0023\n",
            "Train Loss: 0.00232145469635725\n",
            "Saved\n",
            "Means:  [ 0.10792672  0.09801126 -0.05621481 -0.10737261 -0.03551742  0.07576988]\n",
            "Evals:  [5.26890941 3.78685395 3.63148425 3.53566292 3.40914091 3.22826114]\n",
            "Epoch 300\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 87ms/step - loss: 0.0023\n",
            "Train Loss: 0.0023396622855216265\n",
            "Epoch 301\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0023\n",
            "Train Loss: 0.0023373770527541637\n",
            "Epoch 302\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0023\n",
            "Train Loss: 0.0023349192924797535\n",
            "Epoch 303\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0023\n",
            "Train Loss: 0.002327501308172941\n",
            "Epoch 304\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0023\n",
            "Train Loss: 0.0023253443650901318\n",
            "Epoch 305\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0023\n",
            "Train Loss: 0.0023200849536806345\n",
            "Epoch 306\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0023\n",
            "Train Loss: 0.002333038719370961\n",
            "Epoch 307\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0023\n",
            "Train Loss: 0.0023238915018737316\n",
            "Epoch 308\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0023\n",
            "Train Loss: 0.002307808492332697\n",
            "Epoch 309\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0023\n",
            "Train Loss: 0.0022795891854912043\n",
            "Epoch 310\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0023\n",
            "Train Loss: 0.0022619955707341433\n",
            "Epoch 311\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0022\n",
            "Train Loss: 0.0022379399742931128\n",
            "Epoch 312\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0022\n",
            "Train Loss: 0.002227987162768841\n",
            "Epoch 313\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0022\n",
            "Train Loss: 0.002220380352810025\n",
            "Epoch 314\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0022\n",
            "Train Loss: 0.0022378007415682077\n",
            "Epoch 315\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0023\n",
            "Train Loss: 0.002252837410196662\n",
            "Epoch 316\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 87ms/step - loss: 0.0023\n",
            "Train Loss: 0.002254876773804426\n",
            "Epoch 317\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0022\n",
            "Train Loss: 0.0022218297235667706\n",
            "Epoch 318\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0022\n",
            "Train Loss: 0.0022348547354340553\n",
            "Epoch 319\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0022\n",
            "Train Loss: 0.0022335564717650414\n",
            "Epoch 320\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0023\n",
            "Train Loss: 0.002254253486171365\n",
            "Epoch 321\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0023\n",
            "Train Loss: 0.002266744151711464\n",
            "Epoch 322\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0022\n",
            "Train Loss: 0.002241828478872776\n",
            "Epoch 323\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0022\n",
            "Train Loss: 0.002206140197813511\n",
            "Epoch 324\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0022\n",
            "Train Loss: 0.0021801183465868235\n",
            "Epoch 325\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0022\n",
            "Train Loss: 0.0021623915527015924\n",
            "Epoch 326\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0021\n",
            "Train Loss: 0.0021472175139933825\n",
            "Epoch 327\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0022\n",
            "Train Loss: 0.0021520282607525587\n",
            "Epoch 328\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0022\n",
            "Train Loss: 0.0021597540471702814\n",
            "Epoch 329\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 83ms/step - loss: 0.0022\n",
            "Train Loss: 0.0021772391628473997\n",
            "Epoch 330\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0022\n",
            "Train Loss: 0.0021776119247078896\n",
            "Epoch 331\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0022\n",
            "Train Loss: 0.002166127786040306\n",
            "Epoch 332\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0021\n",
            "Train Loss: 0.002148105064406991\n",
            "Epoch 333\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0021\n",
            "Train Loss: 0.0021470135543495417\n",
            "Epoch 334\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0021\n",
            "Train Loss: 0.0021391951013356447\n",
            "Epoch 335\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0021\n",
            "Train Loss: 0.0021341678220778704\n",
            "Epoch 336\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0021\n",
            "Train Loss: 0.0021466289181262255\n",
            "Epoch 337\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 0.0022\n",
            "Train Loss: 0.002160614589229226\n",
            "Epoch 338\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0022\n",
            "Train Loss: 0.002154783345758915\n",
            "Epoch 339\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0022\n",
            "Train Loss: 0.0021576189901679754\n",
            "Epoch 340\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0021\n",
            "Train Loss: 0.002146941376850009\n",
            "Epoch 341\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0021\n",
            "Train Loss: 0.0021323824767023325\n",
            "Epoch 342\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0021\n",
            "Train Loss: 0.0021307861898094416\n",
            "Epoch 343\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 0.0021\n",
            "Train Loss: 0.0021218089386820793\n",
            "Epoch 344\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0021\n",
            "Train Loss: 0.0021195802837610245\n",
            "Epoch 345\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0021\n",
            "Train Loss: 0.002116433810442686\n",
            "Epoch 346\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0021\n",
            "Train Loss: 0.002101919846609235\n",
            "Epoch 347\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0021\n",
            "Train Loss: 0.0020833490416407585\n",
            "Epoch 348\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0021\n",
            "Train Loss: 0.002080649370327592\n",
            "Epoch 349\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0021\n",
            "Train Loss: 0.002069673966616392\n",
            "Saved\n",
            "Means:  [-0.1982865  -0.07941668 -0.02075031  0.05500107 -0.08955497 -0.06053233]\n",
            "Evals:  [5.05178185 3.72898938 3.68292989 3.49302136 3.36484979 3.29854563]\n",
            "Epoch 350\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 77ms/step - loss: 0.0021\n",
            "Train Loss: 0.0020958485547453165\n",
            "Epoch 351\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0021\n",
            "Train Loss: 0.002134936163201928\n",
            "Epoch 352\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0021\n",
            "Train Loss: 0.002121471567079425\n",
            "Epoch 353\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0021\n",
            "Train Loss: 0.002121712313964963\n",
            "Epoch 354\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0021\n",
            "Train Loss: 0.002106097526848316\n",
            "Epoch 355\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0021\n",
            "Train Loss: 0.0020952499471604824\n",
            "Epoch 356\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0021\n",
            "Train Loss: 0.0020694024860858917\n",
            "Epoch 357\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0021\n",
            "Train Loss: 0.002069158013910055\n",
            "Epoch 358\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0020\n",
            "Train Loss: 0.002040211809799075\n",
            "Epoch 359\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0020\n",
            "Train Loss: 0.002034639474004507\n",
            "Epoch 360\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0020\n",
            "Train Loss: 0.002016236539930105\n",
            "Epoch 361\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0020\n",
            "Train Loss: 0.002046598820015788\n",
            "Epoch 362\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0020\n",
            "Train Loss: 0.0020404134411364794\n",
            "Epoch 363\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0021\n",
            "Train Loss: 0.002063626190647483\n",
            "Epoch 364\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0021\n",
            "Train Loss: 0.0020814924500882626\n",
            "Epoch 365\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0021\n",
            "Train Loss: 0.002086640801280737\n",
            "Epoch 366\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0021\n",
            "Train Loss: 0.002068825764581561\n",
            "Epoch 367\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0020\n",
            "Train Loss: 0.0020335207227617502\n",
            "Epoch 368\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0020\n",
            "Train Loss: 0.002013328019529581\n",
            "Epoch 369\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0020\n",
            "Train Loss: 0.0020057635847479105\n",
            "Epoch 370\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0020\n",
            "Train Loss: 0.0020012622699141502\n",
            "Epoch 371\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0020\n",
            "Train Loss: 0.0019814963452517986\n",
            "Epoch 372\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 0.0020\n",
            "Train Loss: 0.0019770273938775063\n",
            "Epoch 373\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0020\n",
            "Train Loss: 0.001968525815755129\n",
            "Epoch 374\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0020\n",
            "Train Loss: 0.0019890633411705494\n",
            "Epoch 375\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0020\n",
            "Train Loss: 0.0019918950274586678\n",
            "Epoch 376\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0020\n",
            "Train Loss: 0.001968527212738991\n",
            "Epoch 377\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0020\n",
            "Train Loss: 0.0019588659051805735\n",
            "Epoch 378\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 0.0020\n",
            "Train Loss: 0.0019713719375431538\n",
            "Epoch 379\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0020\n",
            "Train Loss: 0.0019665516447275877\n",
            "Epoch 380\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0020\n",
            "Train Loss: 0.00197035213932395\n",
            "Epoch 381\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0020\n",
            "Train Loss: 0.0019797557033598423\n",
            "Epoch 382\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0020\n",
            "Train Loss: 0.0019696224480867386\n",
            "Epoch 383\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0020\n",
            "Train Loss: 0.0019690212793648243\n",
            "Epoch 384\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0020\n",
            "Train Loss: 0.001965202856808901\n",
            "Epoch 385\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0020\n",
            "Train Loss: 0.001951592625118792\n",
            "Epoch 386\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0019\n",
            "Train Loss: 0.0019383503822609782\n",
            "Epoch 387\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0019\n",
            "Train Loss: 0.0019407756626605988\n",
            "Epoch 388\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0020\n",
            "Train Loss: 0.0019620757084339857\n",
            "Epoch 389\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0019\n",
            "Train Loss: 0.0019415195565670729\n",
            "Epoch 390\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0019\n",
            "Train Loss: 0.0019441493786871433\n",
            "Epoch 391\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0019\n",
            "Train Loss: 0.0019230638863518834\n",
            "Epoch 392\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0019\n",
            "Train Loss: 0.0019255613442510366\n",
            "Epoch 393\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 0.0019\n",
            "Train Loss: 0.001921202172525227\n",
            "Epoch 394\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0019\n",
            "Train Loss: 0.0019077570177614689\n",
            "Epoch 395\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0019\n",
            "Train Loss: 0.001898647053167224\n",
            "Epoch 396\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0019\n",
            "Train Loss: 0.0018987752264365554\n",
            "Epoch 397\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0019\n",
            "Train Loss: 0.001895760651677847\n",
            "Epoch 398\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0019\n",
            "Train Loss: 0.0018963933689519763\n",
            "Epoch 399\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0019\n",
            "Train Loss: 0.0018971064127981663\n",
            "Saved\n",
            "Means:  [-0.03480712 -0.03953112 -0.17808853 -0.03986238 -0.11172561 -0.10698724]\n",
            "Evals:  [4.85686498 3.6601789  3.42266331 3.37592381 3.30989644 3.23302199]\n",
            "Epoch 400\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 0.0019\n",
            "Train Loss: 0.0018816646188497543\n",
            "Epoch 401\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0019\n",
            "Train Loss: 0.0018674277234822512\n",
            "Epoch 402\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0019\n",
            "Train Loss: 0.0018568316008895636\n",
            "Epoch 403\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0018\n",
            "Train Loss: 0.0018445095047354698\n",
            "Epoch 404\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0018\n",
            "Train Loss: 0.0018286469858139753\n",
            "Epoch 405\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0018\n",
            "Train Loss: 0.0018479992868378758\n",
            "Epoch 406\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0018\n",
            "Train Loss: 0.0018318971851840615\n",
            "Epoch 407\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0018\n",
            "Train Loss: 0.001829233835451305\n",
            "Epoch 408\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 17s 90ms/step - loss: 0.0018\n",
            "Train Loss: 0.0018159108003601432\n",
            "Epoch 409\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0018\n",
            "Train Loss: 0.0018289501313120127\n",
            "Epoch 410\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0018\n",
            "Train Loss: 0.0018453513039276004\n",
            "Epoch 411\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0018\n",
            "Train Loss: 0.00183503283187747\n",
            "Epoch 412\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0018\n",
            "Train Loss: 0.0018275383627042174\n",
            "Epoch 413\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 0.0018\n",
            "Train Loss: 0.0018232193542644382\n",
            "Epoch 414\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0018\n",
            "Train Loss: 0.0018344371346756816\n",
            "Epoch 415\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0018\n",
            "Train Loss: 0.0018066440243273973\n",
            "Epoch 416\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0018\n",
            "Train Loss: 0.0018105489434674382\n",
            "Epoch 417\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0018\n",
            "Train Loss: 0.0018015943933278322\n",
            "Epoch 418\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0018\n",
            "Train Loss: 0.00179180852137506\n",
            "Epoch 419\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0018\n",
            "Train Loss: 0.0017944881692528725\n",
            "Epoch 420\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0018\n",
            "Train Loss: 0.0017784943338483572\n",
            "Epoch 421\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0018\n",
            "Train Loss: 0.001777080469764769\n",
            "Epoch 422\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0018\n",
            "Train Loss: 0.0017722074408084154\n",
            "Epoch 423\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0018\n",
            "Train Loss: 0.0018048688070848584\n",
            "Epoch 424\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0018\n",
            "Train Loss: 0.0018090110970661044\n",
            "Epoch 425\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0018\n",
            "Train Loss: 0.0018202835926786065\n",
            "Epoch 426\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0018\n",
            "Train Loss: 0.0018090916564688087\n",
            "Epoch 427\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0018\n",
            "Train Loss: 0.0018084620824083686\n",
            "Epoch 428\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0018\n",
            "Train Loss: 0.0017975426744669676\n",
            "Epoch 429\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 0.0018\n",
            "Train Loss: 0.0017995340749621391\n",
            "Epoch 430\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0018\n",
            "Train Loss: 0.0017990826163440943\n",
            "Epoch 431\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0018\n",
            "Train Loss: 0.0018019413109868765\n",
            "Epoch 432\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0018\n",
            "Train Loss: 0.0018017812399193645\n",
            "Epoch 433\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0018\n",
            "Train Loss: 0.0018016721587628126\n",
            "Epoch 434\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0018\n",
            "Train Loss: 0.001795019838027656\n",
            "Epoch 435\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 0.0018\n",
            "Train Loss: 0.0017903689295053482\n",
            "Epoch 436\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0018\n",
            "Train Loss: 0.0017865578411146998\n",
            "Epoch 437\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0018\n",
            "Train Loss: 0.0017765306401997805\n",
            "Epoch 438\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0018\n",
            "Train Loss: 0.0017696014838293195\n",
            "Epoch 439\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0018\n",
            "Train Loss: 0.001765212044119835\n",
            "Epoch 440\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0017\n",
            "Train Loss: 0.0017400013748556376\n",
            "Epoch 441\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0017\n",
            "Train Loss: 0.0017272003460675478\n",
            "Epoch 442\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0017\n",
            "Train Loss: 0.001711163786239922\n",
            "Epoch 443\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0017\n",
            "Train Loss: 0.0017030253075063229\n",
            "Epoch 444\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0017\n",
            "Train Loss: 0.0016834383131936193\n",
            "Epoch 445\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 0.0017\n",
            "Train Loss: 0.0016823760233819485\n",
            "Epoch 446\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0017\n",
            "Train Loss: 0.001683683949522674\n",
            "Epoch 447\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0017\n",
            "Train Loss: 0.0016966545954346657\n",
            "Epoch 448\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0017\n",
            "Train Loss: 0.0017047310248017311\n",
            "Epoch 449\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0017\n",
            "Train Loss: 0.0017159113194793463\n",
            "Saved\n",
            "Means:  [ 0.0238628   0.04579716  0.01657192  0.02626783 -0.00686178  0.13376307]\n",
            "Evals:  [4.69463309 3.63348364 3.45026586 3.35188028 3.24764387 3.23015247]\n",
            "Epoch 450\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 75ms/step - loss: 0.0017\n",
            "Train Loss: 0.0017196077387779951\n",
            "Epoch 451\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0017\n",
            "Train Loss: 0.001738844090141356\n",
            "Epoch 452\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0018\n",
            "Train Loss: 0.0017543843714520335\n",
            "Epoch 453\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0018\n",
            "Train Loss: 0.001765044522471726\n",
            "Epoch 454\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 0.0017\n",
            "Train Loss: 0.001749158720485866\n",
            "Epoch 455\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0017\n",
            "Train Loss: 0.00172078562900424\n",
            "Epoch 456\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0017\n",
            "Train Loss: 0.0017387497937306762\n",
            "Epoch 457\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0017\n",
            "Train Loss: 0.0017399541102349758\n",
            "Epoch 458\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0017\n",
            "Train Loss: 0.0017366294050589204\n",
            "Epoch 459\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0017\n",
            "Train Loss: 0.0017242010217159986\n",
            "Epoch 460\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0017\n",
            "Train Loss: 0.0017425488913431764\n",
            "Epoch 461\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0017\n",
            "Train Loss: 0.0017273830017074943\n",
            "Epoch 462\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0017\n",
            "Train Loss: 0.0017299257451668382\n",
            "Epoch 463\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0017\n",
            "Train Loss: 0.00172817416023463\n",
            "Epoch 464\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 0.0017\n",
            "Train Loss: 0.0017079442040994763\n",
            "Epoch 465\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0017\n",
            "Train Loss: 0.0016913047293201089\n",
            "Epoch 466\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0017\n",
            "Train Loss: 0.0016778145218268037\n",
            "Epoch 467\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0017\n",
            "Train Loss: 0.001664632000029087\n",
            "Epoch 468\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0017\n",
            "Train Loss: 0.0016819265438243747\n",
            "Epoch 469\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0017\n",
            "Train Loss: 0.0016884254291653633\n",
            "Epoch 470\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 0.0017\n",
            "Train Loss: 0.0016982505330815911\n",
            "Epoch 471\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0017\n",
            "Train Loss: 0.0016920316265895963\n",
            "Epoch 472\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0017\n",
            "Train Loss: 0.0016949116252362728\n",
            "Epoch 473\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0017\n",
            "Train Loss: 0.001681998372077942\n",
            "Epoch 474\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0017\n",
            "Train Loss: 0.001679076929576695\n",
            "Epoch 475\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0017\n",
            "Train Loss: 0.001681100344285369\n",
            "Epoch 476\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0017\n",
            "Train Loss: 0.0016664126887917519\n",
            "Epoch 477\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0017\n",
            "Train Loss: 0.0016759965801611543\n",
            "Epoch 478\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0017\n",
            "Train Loss: 0.0016772296512499452\n",
            "Epoch 479\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0017\n",
            "Train Loss: 0.0016828678781166673\n",
            "Epoch 480\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0017\n",
            "Train Loss: 0.0016829560045152903\n",
            "Epoch 481\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0017\n",
            "Train Loss: 0.0016622432740405202\n",
            "Epoch 482\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0017\n",
            "Train Loss: 0.0016603729454800487\n",
            "Epoch 483\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0017\n",
            "Train Loss: 0.0016543089877814054\n",
            "Epoch 484\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0017\n",
            "Train Loss: 0.0016531858127564192\n",
            "Epoch 485\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0017\n",
            "Train Loss: 0.0016577222850173712\n",
            "Epoch 486\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0017\n",
            "Train Loss: 0.0016605808632448316\n",
            "Epoch 487\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 0.0017\n",
            "Train Loss: 0.001658463035710156\n",
            "Epoch 488\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0017\n",
            "Train Loss: 0.001660090172663331\n",
            "Epoch 489\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0017\n",
            "Train Loss: 0.0016644775168970227\n",
            "Epoch 490\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0017\n",
            "Train Loss: 0.001662162016145885\n",
            "Epoch 491\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0017\n",
            "Train Loss: 0.001656353590078652\n",
            "Epoch 492\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0017\n",
            "Train Loss: 0.0016618683002889156\n",
            "Epoch 493\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0017\n",
            "Train Loss: 0.0016542039811611176\n",
            "Epoch 494\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0017\n",
            "Train Loss: 0.0016721755964681506\n",
            "Epoch 495\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0017\n",
            "Train Loss: 0.0016637853113934398\n",
            "Epoch 496\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0017\n",
            "Train Loss: 0.001660957932472229\n",
            "Epoch 497\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0017\n",
            "Train Loss: 0.0016661626286804676\n",
            "Epoch 498\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0016\n",
            "Train Loss: 0.0016439995961263776\n",
            "Epoch 499\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0016\n",
            "Train Loss: 0.0016191840404644608\n",
            "Saved\n",
            "Means:  [-0.06688571  0.12637042 -0.01542397 -0.13855587 -0.07779292  0.07158175]\n",
            "Evals:  [4.43118053 3.74635486 3.48975835 3.40388296 3.32103639 3.18181478]\n",
            "Epoch 500\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 76ms/step - loss: 0.0016\n",
            "Train Loss: 0.0016023401403799653\n",
            "Epoch 501\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0016\n",
            "Train Loss: 0.0015983672346919775\n",
            "Epoch 502\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0016\n",
            "Train Loss: 0.0015740637900307775\n",
            "Epoch 503\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0016\n",
            "Train Loss: 0.0015581639017909765\n",
            "Epoch 504\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0016\n",
            "Train Loss: 0.0015623170183971524\n",
            "Epoch 505\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0016\n",
            "Train Loss: 0.001558121177367866\n",
            "Epoch 506\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 0.0016\n",
            "Train Loss: 0.0015598362078890204\n",
            "Epoch 507\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0016\n",
            "Train Loss: 0.0015586183872073889\n",
            "Epoch 508\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0016\n",
            "Train Loss: 0.0015610757982358336\n",
            "Epoch 509\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0016\n",
            "Train Loss: 0.0015766650903970003\n",
            "Epoch 510\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0016\n",
            "Train Loss: 0.001604315941222012\n",
            "Epoch 511\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0016\n",
            "Train Loss: 0.0016108439303934574\n",
            "Epoch 512\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0016\n",
            "Train Loss: 0.001590271363966167\n",
            "Epoch 513\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0016\n",
            "Train Loss: 0.0015975461574271321\n",
            "Epoch 514\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0016\n",
            "Train Loss: 0.001568104256875813\n",
            "Epoch 515\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0016\n",
            "Train Loss: 0.001556749572046101\n",
            "Epoch 516\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0016\n",
            "Train Loss: 0.0015666126273572445\n",
            "Epoch 517\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0015\n",
            "Train Loss: 0.0015400038100779057\n",
            "Epoch 518\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0015\n",
            "Train Loss: 0.0015328509034588933\n",
            "Epoch 519\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0015\n",
            "Train Loss: 0.0015240169595927\n",
            "Epoch 520\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0015\n",
            "Train Loss: 0.0015235594473779202\n",
            "Epoch 521\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0015\n",
            "Train Loss: 0.0015201939968392253\n",
            "Epoch 522\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0015\n",
            "Train Loss: 0.0015147975645959377\n",
            "Epoch 523\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0015\n",
            "Train Loss: 0.0015022290172055364\n",
            "Epoch 524\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0015\n",
            "Train Loss: 0.0014878218062222004\n",
            "Epoch 525\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0015\n",
            "Train Loss: 0.0014970987103879452\n",
            "Epoch 526\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 89ms/step - loss: 0.0015\n",
            "Train Loss: 0.001486769411712885\n",
            "Epoch 527\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0015\n",
            "Train Loss: 0.0014798991614952683\n",
            "Epoch 528\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0015\n",
            "Train Loss: 0.0014698364539071918\n",
            "Epoch 529\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 0.0015\n",
            "Train Loss: 0.001464366796426475\n",
            "Epoch 530\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0015\n",
            "Train Loss: 0.0014663152396678925\n",
            "Epoch 531\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0015\n",
            "Train Loss: 0.001466822111979127\n",
            "Epoch 532\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0015\n",
            "Train Loss: 0.0014741187915205956\n",
            "Epoch 533\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0015\n",
            "Train Loss: 0.0014910068130120635\n",
            "Epoch 534\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0015\n",
            "Train Loss: 0.0015008363407105207\n",
            "Epoch 535\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0015\n",
            "Train Loss: 0.0015055310213938355\n",
            "Epoch 536\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0015\n",
            "Train Loss: 0.001475814264267683\n",
            "Epoch 537\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0015\n",
            "Train Loss: 0.0014644532930105925\n",
            "Epoch 538\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0015\n",
            "Train Loss: 0.0014636180130764842\n",
            "Epoch 539\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0015\n",
            "Train Loss: 0.0014636334963142872\n",
            "Epoch 540\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 0.0015\n",
            "Train Loss: 0.0014817091869190335\n",
            "Epoch 541\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0015\n",
            "Train Loss: 0.0014732169220224023\n",
            "Epoch 542\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0015\n",
            "Train Loss: 0.001478357007727027\n",
            "Epoch 543\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0015\n",
            "Train Loss: 0.0014724809443578124\n",
            "Epoch 544\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0015\n",
            "Train Loss: 0.0014882998075336218\n",
            "Epoch 545\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0015\n",
            "Train Loss: 0.00150090001989156\n",
            "Epoch 546\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0015\n",
            "Train Loss: 0.0014980959240347147\n",
            "Epoch 547\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 17s 89ms/step - loss: 0.0015\n",
            "Train Loss: 0.001485787914134562\n",
            "Epoch 548\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0015\n",
            "Train Loss: 0.00147080491296947\n",
            "Epoch 549\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 0.0015\n",
            "Train Loss: 0.001472350093536079\n",
            "Epoch 550\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0015\n",
            "Train Loss: 0.0014664455084130168\n",
            "Epoch 551\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0014\n",
            "Train Loss: 0.001447901944629848\n",
            "Epoch 552\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 0.0014\n",
            "Train Loss: 0.0014347595861181617\n",
            "Epoch 553\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0014\n",
            "Train Loss: 0.0014224208425730467\n",
            "Epoch 554\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0014\n",
            "Train Loss: 0.0014088063035160303\n",
            "Epoch 555\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0014\n",
            "Train Loss: 0.001409008982591331\n",
            "Epoch 556\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0014\n",
            "Train Loss: 0.001412461861036718\n",
            "Epoch 557\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0014\n",
            "Train Loss: 0.0014192401431500912\n",
            "Epoch 558\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 0.0014\n",
            "Train Loss: 0.001407662988640368\n",
            "Epoch 559\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0014\n",
            "Train Loss: 0.001396552543155849\n",
            "Epoch 560\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0014\n",
            "Train Loss: 0.001391131430864334\n",
            "Epoch 561\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0014\n",
            "Train Loss: 0.0013780307490378618\n",
            "Epoch 562\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0014\n",
            "Train Loss: 0.0013817467261105776\n",
            "Epoch 563\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0014\n",
            "Train Loss: 0.0013757575070485473\n",
            "Epoch 564\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0014\n",
            "Train Loss: 0.001358719659037888\n",
            "Epoch 565\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0014\n",
            "Train Loss: 0.0013721551513299346\n",
            "Epoch 566\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0014\n",
            "Train Loss: 0.0013862894847989082\n",
            "Epoch 567\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 87ms/step - loss: 0.0014\n",
            "Train Loss: 0.001397401443682611\n",
            "Epoch 568\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0014\n",
            "Train Loss: 0.0014086990850046277\n",
            "Epoch 569\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 0.0014\n",
            "Train Loss: 0.001422798610292375\n",
            "Epoch 570\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0014\n",
            "Train Loss: 0.0014105710433796048\n",
            "Epoch 571\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0014\n",
            "Train Loss: 0.0013960829237475991\n",
            "Epoch 572\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0014\n",
            "Train Loss: 0.00138064322527498\n",
            "Epoch 573\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 0.0014\n",
            "Train Loss: 0.0013898632023483515\n",
            "Epoch 574\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0014\n",
            "Train Loss: 0.001380978268571198\n",
            "Epoch 575\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0014\n",
            "Train Loss: 0.0013866395456716418\n",
            "Epoch 576\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0014\n",
            "Train Loss: 0.0013884484069421887\n",
            "Epoch 577\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0014\n",
            "Train Loss: 0.001395202474668622\n",
            "Epoch 578\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0014\n",
            "Train Loss: 0.0013787639327347279\n",
            "Epoch 579\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 0.0014\n",
            "Train Loss: 0.0013792415848001838\n",
            "Epoch 580\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0014\n",
            "Train Loss: 0.0013683843426406384\n",
            "Epoch 581\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0013\n",
            "Train Loss: 0.0013364318292587996\n",
            "Epoch 582\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0013\n",
            "Train Loss: 0.001334737055003643\n",
            "Epoch 583\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0013\n",
            "Train Loss: 0.0013393375556915998\n",
            "Epoch 584\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0013\n",
            "Train Loss: 0.001347481505945325\n",
            "Epoch 585\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0014\n",
            "Train Loss: 0.0013648162130266428\n",
            "Epoch 586\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0014\n",
            "Train Loss: 0.001363734365440905\n",
            "Epoch 587\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0013\n",
            "Train Loss: 0.001346884062513709\n",
            "Epoch 588\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0013\n",
            "Train Loss: 0.0013280902057886124\n",
            "Epoch 589\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 87ms/step - loss: 0.0013\n",
            "Train Loss: 0.0013183124829083681\n",
            "Epoch 590\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0013\n",
            "Train Loss: 0.0013259529368951917\n",
            "Epoch 591\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0013\n",
            "Train Loss: 0.0013291523791849613\n",
            "Epoch 592\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0013\n",
            "Train Loss: 0.001323360949754715\n",
            "Epoch 593\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0013\n",
            "Train Loss: 0.0013362764148041606\n",
            "Epoch 594\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 0.0014\n",
            "Train Loss: 0.0013509137788787484\n",
            "Epoch 595\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0014\n",
            "Train Loss: 0.0013534285826608539\n",
            "Epoch 596\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0014\n",
            "Train Loss: 0.0013535154284909368\n",
            "Epoch 597\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0014\n",
            "Train Loss: 0.0013523786328732967\n",
            "Epoch 598\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0014\n",
            "Train Loss: 0.0013686723541468382\n",
            "Epoch 599\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0014\n",
            "Train Loss: 0.001368056982755661\n",
            "Saved\n",
            "Means:  [ 0.01533599 -0.11430804  0.03471624 -0.10672795 -0.02286825  0.10245802]\n",
            "Evals:  [4.2094199  3.46634852 3.33110675 3.24764617 3.20825396 3.12175945]\n",
            "Epoch 600\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 0.0013\n",
            "Train Loss: 0.0013470040867105126\n",
            "Epoch 601\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0014\n",
            "Train Loss: 0.0013511336874216795\n",
            "Epoch 602\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0013\n",
            "Train Loss: 0.001336886896751821\n",
            "Epoch 603\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0014\n",
            "Train Loss: 0.0013624228304252028\n",
            "Epoch 604\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0014\n",
            "Train Loss: 0.0013547834241762757\n",
            "Epoch 605\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0014\n",
            "Train Loss: 0.001356414402835071\n",
            "Epoch 606\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0014\n",
            "Train Loss: 0.0013529672287404537\n",
            "Epoch 607\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 0.0013\n",
            "Train Loss: 0.0013472611317411065\n",
            "Epoch 608\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 0.0013\n",
            "Train Loss: 0.0013245120644569397\n",
            "Epoch 609\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0013\n",
            "Train Loss: 0.0013236847007647157\n",
            "Epoch 610\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0013\n",
            "Train Loss: 0.0012902063317596912\n",
            "Epoch 611\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0013\n",
            "Train Loss: 0.0012726322747766972\n",
            "Epoch 612\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0013\n",
            "Train Loss: 0.0012522886972874403\n",
            "Epoch 613\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0012\n",
            "Train Loss: 0.0012441144790500402\n",
            "Epoch 614\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 0.0013\n",
            "Train Loss: 0.0012546568177640438\n",
            "Epoch 615\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0013\n",
            "Train Loss: 0.0012663401430472732\n",
            "Epoch 616\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0013\n",
            "Train Loss: 0.0012634360464289784\n",
            "Epoch 617\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0013\n",
            "Train Loss: 0.0012675287434831262\n",
            "Epoch 618\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0013\n",
            "Train Loss: 0.0012668592389672995\n",
            "Epoch 619\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0013\n",
            "Train Loss: 0.00125489616766572\n",
            "Epoch 620\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 0.0013\n",
            "Train Loss: 0.0012502456083893776\n",
            "Epoch 621\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0013\n",
            "Train Loss: 0.001255343551747501\n",
            "Epoch 622\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0012\n",
            "Train Loss: 0.0012396066449582577\n",
            "Epoch 623\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0012\n",
            "Train Loss: 0.0012299236841499805\n",
            "Epoch 624\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0012\n",
            "Train Loss: 0.0012160876067355275\n",
            "Epoch 625\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0012\n",
            "Train Loss: 0.0012152938870713115\n",
            "Epoch 626\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0012\n",
            "Train Loss: 0.0012234387686476111\n",
            "Epoch 627\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 87ms/step - loss: 0.0012\n",
            "Train Loss: 0.001241533551365137\n",
            "Epoch 628\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 0.0012\n",
            "Train Loss: 0.0012415347155183554\n",
            "Epoch 629\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0012\n",
            "Train Loss: 0.00122677197214216\n",
            "Epoch 630\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0012\n",
            "Train Loss: 0.0012341481633484364\n",
            "Epoch 631\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0012\n",
            "Train Loss: 0.0012445602333173156\n",
            "Epoch 632\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0012\n",
            "Train Loss: 0.0012406952446326613\n",
            "Epoch 633\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0012\n",
            "Train Loss: 0.0012302944669499993\n",
            "Epoch 634\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0012\n",
            "Train Loss: 0.0012118032900616527\n",
            "Epoch 635\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 0.0012\n",
            "Train Loss: 0.0011875119525939226\n",
            "Epoch 636\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0012\n",
            "Train Loss: 0.0011702668853104115\n",
            "Epoch 637\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0012\n",
            "Train Loss: 0.0011622722959145904\n",
            "Epoch 638\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0012\n",
            "Train Loss: 0.001159246196039021\n",
            "Epoch 639\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0012\n",
            "Train Loss: 0.001173924538306892\n",
            "Epoch 640\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0012\n",
            "Train Loss: 0.0011758985929191113\n",
            "Epoch 641\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0012\n",
            "Train Loss: 0.001166632049717009\n",
            "Epoch 642\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0012\n",
            "Train Loss: 0.0011644952464848757\n",
            "Epoch 643\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0012\n",
            "Train Loss: 0.0011522455606609583\n",
            "Epoch 644\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0011\n",
            "Train Loss: 0.001135572325438261\n",
            "Epoch 645\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0011\n",
            "Train Loss: 0.0011289484100416303\n",
            "Epoch 646\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0011\n",
            "Train Loss: 0.0011088676983490586\n",
            "Epoch 647\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 87ms/step - loss: 0.0011\n",
            "Train Loss: 0.0010921931825578213\n",
            "Epoch 648\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0011\n",
            "Train Loss: 0.0010993469040840864\n",
            "Epoch 649\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0011\n",
            "Train Loss: 0.0011066950391978025\n",
            "Epoch 650\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0011\n",
            "Train Loss: 0.0011054371716454625\n",
            "Epoch 651\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0011\n",
            "Train Loss: 0.0011320336489006877\n",
            "Epoch 652\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0011\n",
            "Train Loss: 0.0011295984731987119\n",
            "Epoch 653\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0011\n",
            "Train Loss: 0.0011232619872316718\n",
            "Epoch 654\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0011\n",
            "Train Loss: 0.0011075969086959958\n",
            "Epoch 655\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0011\n",
            "Train Loss: 0.0011292201234027743\n",
            "Epoch 656\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0011\n",
            "Train Loss: 0.001115882070735097\n",
            "Epoch 657\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0011\n",
            "Train Loss: 0.0011339770862832665\n",
            "Epoch 658\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0011\n",
            "Train Loss: 0.0011256238212808967\n",
            "Epoch 659\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0011\n",
            "Train Loss: 0.0011257216101512313\n",
            "Epoch 660\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0011\n",
            "Train Loss: 0.001119754510000348\n",
            "Epoch 661\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0011\n",
            "Train Loss: 0.001125850947573781\n",
            "Epoch 662\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 0.0011\n",
            "Train Loss: 0.0011202524183318019\n",
            "Epoch 663\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0011\n",
            "Train Loss: 0.0011107961181551218\n",
            "Epoch 664\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0011\n",
            "Train Loss: 0.0011087063467130065\n",
            "Epoch 665\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0011\n",
            "Train Loss: 0.0011055590584874153\n",
            "Epoch 666\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 0.0011\n",
            "Train Loss: 0.0011094319634139538\n",
            "Epoch 667\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 87ms/step - loss: 0.0011\n",
            "Train Loss: 0.001120114466175437\n",
            "Epoch 668\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 0.0011\n",
            "Train Loss: 0.001092621823772788\n",
            "Epoch 669\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0011\n",
            "Train Loss: 0.0011000463273376226\n",
            "Epoch 670\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0011\n",
            "Train Loss: 0.0010875222506001592\n",
            "Epoch 671\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0011\n",
            "Train Loss: 0.0010767800267785788\n",
            "Epoch 672\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 0.0011\n",
            "Train Loss: 0.0010723855812102556\n",
            "Epoch 673\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0010\n",
            "Train Loss: 0.001047974219545722\n",
            "Epoch 674\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0010\n",
            "Train Loss: 0.0010407766094431281\n",
            "Epoch 675\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0010\n",
            "Train Loss: 0.0010453916620463133\n",
            "Epoch 676\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0010\n",
            "Train Loss: 0.0010468234540894628\n",
            "Epoch 677\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 0.0010\n",
            "Train Loss: 0.0010444826912134886\n",
            "Epoch 678\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 0.0010\n",
            "Train Loss: 0.001039372873492539\n",
            "Epoch 679\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0010\n",
            "Train Loss: 0.0010213087080046535\n",
            "Epoch 680\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0010\n",
            "Train Loss: 0.0010264463489875197\n",
            "Epoch 681\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0010\n",
            "Train Loss: 0.0010103537933900952\n",
            "Epoch 682\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0010\n",
            "Train Loss: 0.0010123850079253316\n",
            "Epoch 683\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 87ms/step - loss: 0.0010\n",
            "Train Loss: 0.0010137242497876287\n",
            "Epoch 684\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0010\n",
            "Train Loss: 0.0010155965574085712\n",
            "Epoch 685\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0010\n",
            "Train Loss: 0.0010218349052593112\n",
            "Epoch 686\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0010\n",
            "Train Loss: 0.001007779035717249\n",
            "Epoch 687\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0010\n",
            "Train Loss: 0.0010062871733680367\n",
            "Epoch 688\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 17s 89ms/step - loss: 9.9160e-04\n",
            "Train Loss: 0.0009916010312736034\n",
            "Epoch 689\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 0.0010\n",
            "Train Loss: 0.0010037183528766036\n",
            "Epoch 690\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0010\n",
            "Train Loss: 0.0010019771289080381\n",
            "Epoch 691\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0010\n",
            "Train Loss: 0.0010017406893894076\n",
            "Epoch 692\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 9.8972e-04\n",
            "Train Loss: 0.0009897241834551096\n",
            "Epoch 693\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 9.9035e-04\n",
            "Train Loss: 0.000990353524684906\n",
            "Epoch 694\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 9.8047e-04\n",
            "Train Loss: 0.000980466022156179\n",
            "Epoch 695\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 9.7634e-04\n",
            "Train Loss: 0.0009763359557837248\n",
            "Epoch 696\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 9.7228e-04\n",
            "Train Loss: 0.0009722808026708663\n",
            "Epoch 697\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 9.6912e-04\n",
            "Train Loss: 0.0009691168088465929\n",
            "Epoch 698\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 9.6634e-04\n",
            "Train Loss: 0.000966337975114584\n",
            "Epoch 699\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 9.7344e-04\n",
            "Train Loss: 0.0009734374471008778\n",
            "Saved\n",
            "Means:  [-0.07082806  0.09802346 -0.07031149  0.09529432 -0.01406867  0.12240066]\n",
            "Evals:  [4.02904    3.28781801 3.24881489 3.14925663 3.04687665 2.90340578]\n",
            "Epoch 700\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 9.7251e-04\n",
            "Train Loss: 0.0009725136333145201\n",
            "Epoch 701\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 9.7664e-04\n",
            "Train Loss: 0.000976639916189015\n",
            "Epoch 702\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 9.8084e-04\n",
            "Train Loss: 0.0009808449540287256\n",
            "Epoch 703\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 9.8764e-04\n",
            "Train Loss: 0.0009876389522105455\n",
            "Epoch 704\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 9.7588e-04\n",
            "Train Loss: 0.0009758764645084739\n",
            "Epoch 705\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 9.6480e-04\n",
            "Train Loss: 0.0009648041450418532\n",
            "Epoch 706\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 9.6464e-04\n",
            "Train Loss: 0.000964640115853399\n",
            "Epoch 707\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 9.7917e-04\n",
            "Train Loss: 0.0009791726479306817\n",
            "Epoch 708\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 9.6585e-04\n",
            "Train Loss: 0.000965853629168123\n",
            "Epoch 709\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 9.5262e-04\n",
            "Train Loss: 0.0009526197682134807\n",
            "Epoch 710\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 9.5665e-04\n",
            "Train Loss: 0.0009566502412781119\n",
            "Epoch 711\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 9.5817e-04\n",
            "Train Loss: 0.0009581748745404184\n",
            "Epoch 712\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 9.7370e-04\n",
            "Train Loss: 0.0009737029322423041\n",
            "Epoch 713\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 87ms/step - loss: 9.6800e-04\n",
            "Train Loss: 0.0009680015500634909\n",
            "Epoch 714\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 9.5895e-04\n",
            "Train Loss: 0.0009589516557753086\n",
            "Epoch 715\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 9.6274e-04\n",
            "Train Loss: 0.0009627350955270231\n",
            "Epoch 716\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 9.5244e-04\n",
            "Train Loss: 0.0009524373454041779\n",
            "Epoch 717\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 9.6211e-04\n",
            "Train Loss: 0.0009621058125048876\n",
            "Epoch 718\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 9.5500e-04\n",
            "Train Loss: 0.000955002848058939\n",
            "Epoch 719\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 9.4790e-04\n",
            "Train Loss: 0.0009479033178649843\n",
            "Epoch 720\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 9.3700e-04\n",
            "Train Loss: 0.0009370016632601619\n",
            "Epoch 721\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 9.4369e-04\n",
            "Train Loss: 0.0009436862310394645\n",
            "Epoch 722\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 9.3696e-04\n",
            "Train Loss: 0.0009369601611979306\n",
            "Epoch 723\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 9.3260e-04\n",
            "Train Loss: 0.0009325952851213515\n",
            "Epoch 724\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 9.4008e-04\n",
            "Train Loss: 0.0009400814888067544\n",
            "Epoch 725\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 9.3417e-04\n",
            "Train Loss: 0.0009341650875285268\n",
            "Epoch 726\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 9.2505e-04\n",
            "Train Loss: 0.0009250479051843286\n",
            "Epoch 727\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 9.1777e-04\n",
            "Train Loss: 0.0009177714819088578\n",
            "Epoch 728\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 9.0224e-04\n",
            "Train Loss: 0.0009022391750477254\n",
            "Epoch 729\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 8.8564e-04\n",
            "Train Loss: 0.0008856437052600086\n",
            "Epoch 730\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 8.7060e-04\n",
            "Train Loss: 0.00087059783982113\n",
            "Epoch 731\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 8.6229e-04\n",
            "Train Loss: 0.0008622871246188879\n",
            "Epoch 732\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 8.6337e-04\n",
            "Train Loss: 0.0008633708930574358\n",
            "Epoch 733\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 8.6148e-04\n",
            "Train Loss: 0.000861479842569679\n",
            "Epoch 734\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 8.5901e-04\n",
            "Train Loss: 0.000859013176523149\n",
            "Epoch 735\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 8.8012e-04\n",
            "Train Loss: 0.0008801249205134809\n",
            "Epoch 736\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 8.7790e-04\n",
            "Train Loss: 0.0008778994088061154\n",
            "Epoch 737\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 8.7042e-04\n",
            "Train Loss: 0.0008704211795702577\n",
            "Epoch 738\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 8.6419e-04\n",
            "Train Loss: 0.0008641890599392354\n",
            "Epoch 739\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 87ms/step - loss: 8.5889e-04\n",
            "Train Loss: 0.0008588884957134724\n",
            "Epoch 740\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 8.4834e-04\n",
            "Train Loss: 0.0008483398705720901\n",
            "Epoch 741\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 8.5854e-04\n",
            "Train Loss: 0.000858539598993957\n",
            "Epoch 742\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 8.5933e-04\n",
            "Train Loss: 0.0008593254606239498\n",
            "Epoch 743\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 8.2904e-04\n",
            "Train Loss: 0.0008290406549349427\n",
            "Epoch 744\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 87ms/step - loss: 8.2404e-04\n",
            "Train Loss: 0.0008240440511144698\n",
            "Epoch 745\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 8.3664e-04\n",
            "Train Loss: 0.0008366384427063167\n",
            "Epoch 746\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 8.2709e-04\n",
            "Train Loss: 0.0008270932594314218\n",
            "Epoch 747\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 8.3318e-04\n",
            "Train Loss: 0.0008331752615049481\n",
            "Epoch 748\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 8.5044e-04\n",
            "Train Loss: 0.0008504430879838765\n",
            "Epoch 749\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 8.5157e-04\n",
            "Train Loss: 0.000851570104714483\n",
            "Epoch 750\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 8.5764e-04\n",
            "Train Loss: 0.0008576418622396886\n",
            "Epoch 751\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 8.3160e-04\n",
            "Train Loss: 0.0008315981831401587\n",
            "Epoch 752\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 8.2944e-04\n",
            "Train Loss: 0.0008294381550513208\n",
            "Epoch 753\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 8.1749e-04\n",
            "Train Loss: 0.0008174945833161473\n",
            "Epoch 754\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 7.9923e-04\n",
            "Train Loss: 0.0007992340251803398\n",
            "Epoch 755\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 7.9123e-04\n",
            "Train Loss: 0.0007912301807664335\n",
            "Epoch 756\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 7.9145e-04\n",
            "Train Loss: 0.0007914544548839331\n",
            "Epoch 757\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 7.9756e-04\n",
            "Train Loss: 0.0007975633488968015\n",
            "Epoch 758\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 7.8761e-04\n",
            "Train Loss: 0.0007876139134168625\n",
            "Epoch 759\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 7.7495e-04\n",
            "Train Loss: 0.0007749490905553102\n",
            "Epoch 760\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 7.7619e-04\n",
            "Train Loss: 0.0007761913002468646\n",
            "Epoch 761\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 7.7039e-04\n",
            "Train Loss: 0.0007703916635364294\n",
            "Epoch 762\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 7.7313e-04\n",
            "Train Loss: 0.0007731337682344019\n",
            "Epoch 763\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 7.4441e-04\n",
            "Train Loss: 0.0007444125949405134\n",
            "Epoch 764\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 7.5053e-04\n",
            "Train Loss: 0.0007505335379391909\n",
            "Epoch 765\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 17s 89ms/step - loss: 7.5839e-04\n",
            "Train Loss: 0.0007583916885778308\n",
            "Epoch 766\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 7.5547e-04\n",
            "Train Loss: 0.0007554705953225493\n",
            "Epoch 767\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 7.6098e-04\n",
            "Train Loss: 0.0007609828608110547\n",
            "Epoch 768\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 7.4692e-04\n",
            "Train Loss: 0.0007469230331480503\n",
            "Epoch 769\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 7.5842e-04\n",
            "Train Loss: 0.0007584235863760114\n",
            "Epoch 770\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 7.4626e-04\n",
            "Train Loss: 0.0007462648791261017\n",
            "Epoch 771\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 7.3254e-04\n",
            "Train Loss: 0.0007325353217311203\n",
            "Epoch 772\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 7.3550e-04\n",
            "Train Loss: 0.0007354962290264666\n",
            "Epoch 773\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 7.3934e-04\n",
            "Train Loss: 0.0007393446867354214\n",
            "Epoch 774\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 7.4723e-04\n",
            "Train Loss: 0.0007472332799807191\n",
            "Epoch 775\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 7.7598e-04\n",
            "Train Loss: 0.0007759826839901507\n",
            "Epoch 776\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 7.7462e-04\n",
            "Train Loss: 0.0007746249902993441\n",
            "Epoch 777\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 7.7781e-04\n",
            "Train Loss: 0.0007778125000186265\n",
            "Epoch 778\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 7.5689e-04\n",
            "Train Loss: 0.0007568926084786654\n",
            "Epoch 779\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 7.4892e-04\n",
            "Train Loss: 0.0007489193230867386\n",
            "Epoch 780\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 7.3553e-04\n",
            "Train Loss: 0.0007355305133387446\n",
            "Epoch 781\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 7.1697e-04\n",
            "Train Loss: 0.0007169744931161404\n",
            "Epoch 782\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 7.0602e-04\n",
            "Train Loss: 0.0007060240604914725\n",
            "Epoch 783\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 7.0123e-04\n",
            "Train Loss: 0.0007012314163148403\n",
            "Epoch 784\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 7.0474e-04\n",
            "Train Loss: 0.0007047448889352381\n",
            "Epoch 785\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 7.0786e-04\n",
            "Train Loss: 0.0007078630733303726\n",
            "Epoch 786\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 7.0968e-04\n",
            "Train Loss: 0.0007096831104718149\n",
            "Epoch 787\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 7.0847e-04\n",
            "Train Loss: 0.000708473555278033\n",
            "Epoch 788\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 7.1469e-04\n",
            "Train Loss: 0.0007146914140321314\n",
            "Epoch 789\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 7.1290e-04\n",
            "Train Loss: 0.000712901703082025\n",
            "Epoch 790\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 7.1390e-04\n",
            "Train Loss: 0.000713902642019093\n",
            "Epoch 791\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 6.9804e-04\n",
            "Train Loss: 0.0006980421021580696\n",
            "Epoch 792\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 6.9431e-04\n",
            "Train Loss: 0.000694309186656028\n",
            "Epoch 793\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 6.8230e-04\n",
            "Train Loss: 0.0006822963478043675\n",
            "Epoch 794\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 6.7655e-04\n",
            "Train Loss: 0.0006765506113879383\n",
            "Epoch 795\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 6.7996e-04\n",
            "Train Loss: 0.0006799576221965253\n",
            "Epoch 796\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 6.8742e-04\n",
            "Train Loss: 0.000687422463670373\n",
            "Epoch 797\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 6.9448e-04\n",
            "Train Loss: 0.00069448008434847\n",
            "Epoch 798\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 6.8306e-04\n",
            "Train Loss: 0.000683056190609932\n",
            "Epoch 799\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 6.7462e-04\n",
            "Train Loss: 0.0006746192811988294\n",
            "Saved\n",
            "Means:  [-0.10134719  0.03703244 -0.10248672  0.02349892 -0.08762459  0.04098399]\n",
            "Evals:  [3.79836012 3.21261597 3.15351406 3.01446697 2.91826652 2.83983861]\n",
            "Epoch 800\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 75ms/step - loss: 6.7048e-04\n",
            "Train Loss: 0.0006704834522679448\n",
            "Epoch 801\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 6.5740e-04\n",
            "Train Loss: 0.0006573962164111435\n",
            "Epoch 802\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 6.3050e-04\n",
            "Train Loss: 0.0006305038114078343\n",
            "Epoch 803\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 6.3579e-04\n",
            "Train Loss: 0.0006357911042869091\n",
            "Epoch 804\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 6.3989e-04\n",
            "Train Loss: 0.00063988973852247\n",
            "Epoch 805\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 88ms/step - loss: 6.4183e-04\n",
            "Train Loss: 0.0006418306147679687\n",
            "Epoch 806\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 6.4601e-04\n",
            "Train Loss: 0.0006460117874667048\n",
            "Epoch 807\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 6.3652e-04\n",
            "Train Loss: 0.0006365198642015457\n",
            "Epoch 808\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 6.4241e-04\n",
            "Train Loss: 0.0006424052990041673\n",
            "Epoch 809\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 6.4809e-04\n",
            "Train Loss: 0.0006480931770056486\n",
            "Epoch 810\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 6.4937e-04\n",
            "Train Loss: 0.0006493706023320556\n",
            "Epoch 811\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 6.6061e-04\n",
            "Train Loss: 0.0006606140523217618\n",
            "Epoch 812\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 6.5139e-04\n",
            "Train Loss: 0.0006513919797725976\n",
            "Epoch 813\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 6.6397e-04\n",
            "Train Loss: 0.0006639725179411471\n",
            "Epoch 814\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 6.5184e-04\n",
            "Train Loss: 0.0006518381997011602\n",
            "Epoch 815\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 6.5359e-04\n",
            "Train Loss: 0.0006535885040648282\n",
            "Epoch 816\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 6.3951e-04\n",
            "Train Loss: 0.0006395088275894523\n",
            "Epoch 817\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 6.2762e-04\n",
            "Train Loss: 0.0006276161293499172\n",
            "Epoch 818\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 6.2619e-04\n",
            "Train Loss: 0.0006261900998651981\n",
            "Epoch 819\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 6.3164e-04\n",
            "Train Loss: 0.0006316434592008591\n",
            "Epoch 820\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 87ms/step - loss: 6.3513e-04\n",
            "Train Loss: 0.0006351282936520875\n",
            "Epoch 821\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 6.2113e-04\n",
            "Train Loss: 0.0006211320287548006\n",
            "Epoch 822\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 6.1420e-04\n",
            "Train Loss: 0.0006141964113339782\n",
            "Epoch 823\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 6.2125e-04\n",
            "Train Loss: 0.0006212497828528285\n",
            "Epoch 824\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 6.2487e-04\n",
            "Train Loss: 0.000624867039732635\n",
            "Epoch 825\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 17s 89ms/step - loss: 6.3324e-04\n",
            "Train Loss: 0.0006332364864647388\n",
            "Epoch 826\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 6.3140e-04\n",
            "Train Loss: 0.0006314002675935626\n",
            "Epoch 827\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 6.2206e-04\n",
            "Train Loss: 0.000622059335000813\n",
            "Epoch 828\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 6.2778e-04\n",
            "Train Loss: 0.0006277807406149805\n",
            "Epoch 829\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 6.3188e-04\n",
            "Train Loss: 0.0006318805390037596\n",
            "Epoch 830\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 6.4409e-04\n",
            "Train Loss: 0.000644089886918664\n",
            "Epoch 831\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 6.4257e-04\n",
            "Train Loss: 0.0006425698520615697\n",
            "Epoch 832\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 6.6295e-04\n",
            "Train Loss: 0.0006629519630223513\n",
            "Epoch 833\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 6.8302e-04\n",
            "Train Loss: 0.0006830235361121595\n",
            "Epoch 834\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 6.9396e-04\n",
            "Train Loss: 0.0006939611630514264\n",
            "Epoch 835\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 6.5969e-04\n",
            "Train Loss: 0.0006596909370273352\n",
            "Epoch 836\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 6.4598e-04\n",
            "Train Loss: 0.0006459835567511618\n",
            "Epoch 837\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 6.3755e-04\n",
            "Train Loss: 0.0006375513621605933\n",
            "Epoch 838\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 6.3291e-04\n",
            "Train Loss: 0.0006329123862087727\n",
            "Epoch 839\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 6.2218e-04\n",
            "Train Loss: 0.0006221816292963922\n",
            "Epoch 840\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 6.0968e-04\n",
            "Train Loss: 0.0006096816505305469\n",
            "Epoch 841\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 6.0068e-04\n",
            "Train Loss: 0.0006006834446452558\n",
            "Epoch 842\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 5.9907e-04\n",
            "Train Loss: 0.0005990681820549071\n",
            "Epoch 843\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 5.9714e-04\n",
            "Train Loss: 0.00059713568771258\n",
            "Epoch 844\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 5.8608e-04\n",
            "Train Loss: 0.0005860803066752851\n",
            "Epoch 845\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 88ms/step - loss: 5.8866e-04\n",
            "Train Loss: 0.0005886607686989009\n",
            "Epoch 846\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 87ms/step - loss: 5.7987e-04\n",
            "Train Loss: 0.0005798693164251745\n",
            "Epoch 847\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 5.8579e-04\n",
            "Train Loss: 0.0005857915384694934\n",
            "Epoch 848\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 5.7766e-04\n",
            "Train Loss: 0.0005776645848527551\n",
            "Epoch 849\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 5.8145e-04\n",
            "Train Loss: 0.0005814531468786299\n",
            "Epoch 850\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 5.7541e-04\n",
            "Train Loss: 0.0005754072335548699\n",
            "Epoch 851\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 87ms/step - loss: 5.7125e-04\n",
            "Train Loss: 0.0005712502752430737\n",
            "Epoch 852\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 5.7196e-04\n",
            "Train Loss: 0.0005719568580389023\n",
            "Epoch 853\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 5.6689e-04\n",
            "Train Loss: 0.0005668897647410631\n",
            "Epoch 854\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 5.6556e-04\n",
            "Train Loss: 0.000565557274967432\n",
            "Epoch 855\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 5.6343e-04\n",
            "Train Loss: 0.0005634255358017981\n",
            "Epoch 856\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 5.6192e-04\n",
            "Train Loss: 0.0005619195871986449\n",
            "Epoch 857\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 5.6283e-04\n",
            "Train Loss: 0.0005628312937915325\n",
            "Epoch 858\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 5.8682e-04\n",
            "Train Loss: 0.0005868233856745064\n",
            "Epoch 859\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 5.9073e-04\n",
            "Train Loss: 0.0005907308659516275\n",
            "Epoch 860\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 5.8150e-04\n",
            "Train Loss: 0.0005815015756525099\n",
            "Epoch 861\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 5.6894e-04\n",
            "Train Loss: 0.0005689418758265674\n",
            "Epoch 862\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 5.5528e-04\n",
            "Train Loss: 0.0005552842048928142\n",
            "Epoch 863\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 5.5867e-04\n",
            "Train Loss: 0.000558667175937444\n",
            "Epoch 864\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 5.6985e-04\n",
            "Train Loss: 0.000569851603358984\n",
            "Epoch 865\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 87ms/step - loss: 5.7823e-04\n",
            "Train Loss: 0.0005782287917099893\n",
            "Epoch 866\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 5.7330e-04\n",
            "Train Loss: 0.0005733015132136643\n",
            "Epoch 867\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 5.5962e-04\n",
            "Train Loss: 0.0005596187547780573\n",
            "Epoch 868\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 5.4615e-04\n",
            "Train Loss: 0.0005461510736495256\n",
            "Epoch 869\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 5.3870e-04\n",
            "Train Loss: 0.0005386965349316597\n",
            "Epoch 870\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 5.4290e-04\n",
            "Train Loss: 0.0005428957520052791\n",
            "Epoch 871\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 5.3165e-04\n",
            "Train Loss: 0.0005316510796546936\n",
            "Epoch 872\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 5.3647e-04\n",
            "Train Loss: 0.0005364749813452363\n",
            "Epoch 873\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 5.4593e-04\n",
            "Train Loss: 0.0005459311068989336\n",
            "Epoch 874\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 5.3770e-04\n",
            "Train Loss: 0.0005376950721256435\n",
            "Epoch 875\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 5.2082e-04\n",
            "Train Loss: 0.0005208239308558404\n",
            "Epoch 876\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 5.3738e-04\n",
            "Train Loss: 0.0005373835447244346\n",
            "Epoch 877\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 5.3589e-04\n",
            "Train Loss: 0.000535886618308723\n",
            "Epoch 878\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 5.4168e-04\n",
            "Train Loss: 0.0005416845669969916\n",
            "Epoch 879\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 5.4852e-04\n",
            "Train Loss: 0.0005485212313942611\n",
            "Epoch 880\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 5.3477e-04\n",
            "Train Loss: 0.0005347668193280697\n",
            "Epoch 881\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 5.1355e-04\n",
            "Train Loss: 0.000513550010509789\n",
            "Epoch 882\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 5.0177e-04\n",
            "Train Loss: 0.0005017651710659266\n",
            "Epoch 883\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 4.8725e-04\n",
            "Train Loss: 0.00048725391388870776\n",
            "Epoch 884\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 4.8495e-04\n",
            "Train Loss: 0.0004849482502322644\n",
            "Epoch 885\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 4.8098e-04\n",
            "Train Loss: 0.00048097604303620756\n",
            "Epoch 886\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 4.7742e-04\n",
            "Train Loss: 0.0004774151311721653\n",
            "Epoch 887\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 4.8036e-04\n",
            "Train Loss: 0.0004803562769666314\n",
            "Epoch 888\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 4.7311e-04\n",
            "Train Loss: 0.0004731144290417433\n",
            "Epoch 889\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 78ms/step - loss: 4.7085e-04\n",
            "Train Loss: 0.00047084889956749976\n",
            "Epoch 890\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 4.7744e-04\n",
            "Train Loss: 0.0004774423723574728\n",
            "Epoch 891\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 4.8898e-04\n",
            "Train Loss: 0.0004889823030680418\n",
            "Epoch 892\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 4.9744e-04\n",
            "Train Loss: 0.0004974434268660843\n",
            "Epoch 893\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 4.9147e-04\n",
            "Train Loss: 0.0004914702731184661\n",
            "Epoch 894\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 5.0696e-04\n",
            "Train Loss: 0.0005069623584859073\n",
            "Epoch 895\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 5.0863e-04\n",
            "Train Loss: 0.0005086302990093827\n",
            "Epoch 896\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 5.0439e-04\n",
            "Train Loss: 0.0005043935379944742\n",
            "Epoch 897\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 5.0358e-04\n",
            "Train Loss: 0.0005035815993323922\n",
            "Epoch 898\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 5.0452e-04\n",
            "Train Loss: 0.0005045209545642138\n",
            "Epoch 899\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 5.0538e-04\n",
            "Train Loss: 0.0005053772474639118\n",
            "Saved\n",
            "Means:  [-0.12309004  0.06218982 -0.00359555 -0.1419298   0.04123395 -0.03288877]\n",
            "Evals:  [3.51111021 3.2627865  3.06280085 2.95367604 2.92752247 2.72754913]\n",
            "Epoch 900\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 5.0093e-04\n",
            "Train Loss: 0.0005009331507608294\n",
            "Epoch 901\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 4.9822e-04\n",
            "Train Loss: 0.0004982249229215086\n",
            "Epoch 902\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 4.8062e-04\n",
            "Train Loss: 0.00048061745474115014\n",
            "Epoch 903\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 4.8746e-04\n",
            "Train Loss: 0.00048745732055976987\n",
            "Epoch 904\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 4.8361e-04\n",
            "Train Loss: 0.000483609241200611\n",
            "Epoch 905\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 4.8320e-04\n",
            "Train Loss: 0.0004831989062950015\n",
            "Epoch 906\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 78ms/step - loss: 4.7657e-04\n",
            "Train Loss: 0.0004765679477714002\n",
            "Epoch 907\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 4.7226e-04\n",
            "Train Loss: 0.00047226034803315997\n",
            "Epoch 908\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 4.5851e-04\n",
            "Train Loss: 0.000458510679891333\n",
            "Epoch 909\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 4.5714e-04\n",
            "Train Loss: 0.00045714195584878325\n",
            "Epoch 910\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 78ms/step - loss: 4.4970e-04\n",
            "Train Loss: 0.00044969641021452844\n",
            "Epoch 911\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 4.4304e-04\n",
            "Train Loss: 0.00044304493349045515\n",
            "Epoch 912\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 4.4642e-04\n",
            "Train Loss: 0.0004464239755179733\n",
            "Epoch 913\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 4.4940e-04\n",
            "Train Loss: 0.00044940266525372863\n",
            "Epoch 914\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 78ms/step - loss: 4.6163e-04\n",
            "Train Loss: 0.00046162924263626337\n",
            "Epoch 915\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 78ms/step - loss: 4.5171e-04\n",
            "Train Loss: 0.00045171132660470903\n",
            "Epoch 916\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 78ms/step - loss: 4.5783e-04\n",
            "Train Loss: 0.000457825546618551\n",
            "Epoch 917\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 14s 78ms/step - loss: 4.6346e-04\n",
            "Train Loss: 0.00046346159069798887\n",
            "Epoch 918\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 4.6464e-04\n",
            "Train Loss: 0.0004646396264433861\n",
            "Epoch 919\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 83ms/step - loss: 4.4857e-04\n",
            "Train Loss: 0.0004485712561290711\n",
            "Epoch 920\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 4.5207e-04\n",
            "Train Loss: 0.00045207387302070856\n",
            "Epoch 921\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 84ms/step - loss: 4.4146e-04\n",
            "Train Loss: 0.00044145938591100276\n",
            "Epoch 922\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 4.3515e-04\n",
            "Train Loss: 0.00043514915159903467\n",
            "Epoch 923\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 4.3072e-04\n",
            "Train Loss: 0.0004307173367124051\n",
            "Epoch 924\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 4.3137e-04\n",
            "Train Loss: 0.00043136937892995775\n",
            "Epoch 925\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 87ms/step - loss: 4.2913e-04\n",
            "Train Loss: 0.00042912695789709687\n",
            "Epoch 926\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 4.3572e-04\n",
            "Train Loss: 0.00043572200229391456\n",
            "Epoch 927\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 4.3127e-04\n",
            "Train Loss: 0.00043127129902131855\n",
            "Epoch 928\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 4.3348e-04\n",
            "Train Loss: 0.00043348438339307904\n",
            "Epoch 929\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 4.2531e-04\n",
            "Train Loss: 0.00042531071812845767\n",
            "Epoch 930\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 4.2145e-04\n",
            "Train Loss: 0.0004214474465698004\n",
            "Epoch 931\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 4.2995e-04\n",
            "Train Loss: 0.00042995266267098486\n",
            "Epoch 932\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 4.2659e-04\n",
            "Train Loss: 0.00042658616439439356\n",
            "Epoch 933\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 4.2418e-04\n",
            "Train Loss: 0.0004241827118676156\n",
            "Epoch 934\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 85ms/step - loss: 4.2695e-04\n",
            "Train Loss: 0.00042695263982750475\n",
            "Epoch 935\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 4.2944e-04\n",
            "Train Loss: 0.0004294399986974895\n",
            "Epoch 936\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 4.2276e-04\n",
            "Train Loss: 0.00042275976738892496\n",
            "Epoch 937\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 4.1466e-04\n",
            "Train Loss: 0.0004146632272750139\n",
            "Epoch 938\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 4.1709e-04\n",
            "Train Loss: 0.0004170922620687634\n",
            "Epoch 939\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 81ms/step - loss: 4.2475e-04\n",
            "Train Loss: 0.0004247514298185706\n",
            "Epoch 940\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 4.3357e-04\n",
            "Train Loss: 0.00043356759124435484\n",
            "Epoch 941\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 4.2709e-04\n",
            "Train Loss: 0.0004270850622560829\n",
            "Epoch 942\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 4.2052e-04\n",
            "Train Loss: 0.00042052153730764985\n",
            "Epoch 943\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 4.1714e-04\n",
            "Train Loss: 0.0004171447944827378\n",
            "Epoch 944\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 4.2622e-04\n",
            "Train Loss: 0.0004262151487637311\n",
            "Epoch 945\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 17s 91ms/step - loss: 4.3378e-04\n",
            "Train Loss: 0.0004337778955232352\n",
            "Epoch 946\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 4.3731e-04\n",
            "Train Loss: 0.000437312904978171\n",
            "Epoch 947\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 4.3226e-04\n",
            "Train Loss: 0.00043226376874372363\n",
            "Epoch 948\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 4.3594e-04\n",
            "Train Loss: 0.00043593964073807\n",
            "Epoch 949\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 4.4724e-04\n",
            "Train Loss: 0.00044724272447638214\n",
            "Epoch 950\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 4.4900e-04\n",
            "Train Loss: 0.0004489976563490927\n",
            "Epoch 951\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 4.4790e-04\n",
            "Train Loss: 0.00044789674575440586\n",
            "Epoch 952\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 4.2914e-04\n",
            "Train Loss: 0.0004291350196581334\n",
            "Epoch 953\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 4.4186e-04\n",
            "Train Loss: 0.00044185586739331484\n",
            "Epoch 954\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 78ms/step - loss: 4.5288e-04\n",
            "Train Loss: 0.00045288223191164434\n",
            "Epoch 955\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 4.2969e-04\n",
            "Train Loss: 0.00042969093192368746\n",
            "Epoch 956\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 4.1989e-04\n",
            "Train Loss: 0.0004198855604045093\n",
            "Epoch 957\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 4.1455e-04\n",
            "Train Loss: 0.00041454914025962353\n",
            "Epoch 958\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 4.1091e-04\n",
            "Train Loss: 0.00041091153980232775\n",
            "Epoch 959\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 4.1571e-04\n",
            "Train Loss: 0.000415713555412367\n",
            "Epoch 960\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 4.0679e-04\n",
            "Train Loss: 0.00040679468656890094\n",
            "Epoch 961\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 4.1425e-04\n",
            "Train Loss: 0.00041424750816076994\n",
            "Epoch 962\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 4.1558e-04\n",
            "Train Loss: 0.00041558005614206195\n",
            "Epoch 963\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 4.1778e-04\n",
            "Train Loss: 0.00041777832666411996\n",
            "Epoch 964\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 4.1773e-04\n",
            "Train Loss: 0.00041772672557272017\n",
            "Epoch 965\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 4.2017e-04\n",
            "Train Loss: 0.0004201659467071295\n",
            "Epoch 966\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 88ms/step - loss: 4.0965e-04\n",
            "Train Loss: 0.0004096522752661258\n",
            "Epoch 967\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 4.0700e-04\n",
            "Train Loss: 0.00040700106183066964\n",
            "Epoch 968\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 4.1123e-04\n",
            "Train Loss: 0.00041122979018837214\n",
            "Epoch 969\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 4.0229e-04\n",
            "Train Loss: 0.0004022879002150148\n",
            "Epoch 970\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 3.9765e-04\n",
            "Train Loss: 0.0003976487787440419\n",
            "Epoch 971\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 3.8511e-04\n",
            "Train Loss: 0.0003851069777738303\n",
            "Epoch 972\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 3.8155e-04\n",
            "Train Loss: 0.00038155424408614635\n",
            "Epoch 973\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 3.8472e-04\n",
            "Train Loss: 0.0003847175103146583\n",
            "Epoch 974\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 3.8470e-04\n",
            "Train Loss: 0.0003847019688691944\n",
            "Epoch 975\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 3.8431e-04\n",
            "Train Loss: 0.00038430976564995944\n",
            "Epoch 976\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 3.8295e-04\n",
            "Train Loss: 0.0003829464258160442\n",
            "Epoch 977\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 82ms/step - loss: 3.8513e-04\n",
            "Train Loss: 0.00038512592436745763\n",
            "Epoch 978\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 3.8406e-04\n",
            "Train Loss: 0.00038406398380175233\n",
            "Epoch 979\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 3.8273e-04\n",
            "Train Loss: 0.00038272576057352126\n",
            "Epoch 980\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 3.9624e-04\n",
            "Train Loss: 0.00039623823249712586\n",
            "Epoch 981\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 3.9554e-04\n",
            "Train Loss: 0.00039553921669721603\n",
            "Epoch 982\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 4.0396e-04\n",
            "Train Loss: 0.0004039628547616303\n",
            "Epoch 983\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 4.1523e-04\n",
            "Train Loss: 0.0004152348265051842\n",
            "Epoch 984\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 3.9095e-04\n",
            "Train Loss: 0.000390949979191646\n",
            "Epoch 985\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 3.9154e-04\n",
            "Train Loss: 0.00039153799298219383\n",
            "Epoch 986\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 17s 90ms/step - loss: 3.8841e-04\n",
            "Train Loss: 0.0003884145990014076\n",
            "Epoch 987\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 3.9194e-04\n",
            "Train Loss: 0.00039194460259750485\n",
            "Epoch 988\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 3.8332e-04\n",
            "Train Loss: 0.0003833190421573818\n",
            "Epoch 989\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 3.7952e-04\n",
            "Train Loss: 0.0003795245138462633\n",
            "Epoch 990\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 3.7793e-04\n",
            "Train Loss: 0.00037792653893120587\n",
            "Epoch 991\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 3.8226e-04\n",
            "Train Loss: 0.0003822584403678775\n",
            "Epoch 992\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 86ms/step - loss: 3.7504e-04\n",
            "Train Loss: 0.0003750377509277314\n",
            "Epoch 993\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 3.7101e-04\n",
            "Train Loss: 0.0003710108867380768\n",
            "Epoch 994\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 3.7034e-04\n",
            "Train Loss: 0.0003703363472595811\n",
            "Epoch 995\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 79ms/step - loss: 3.7052e-04\n",
            "Train Loss: 0.00037051778053864837\n",
            "Epoch 996\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 3.7196e-04\n",
            "Train Loss: 0.00037196322227828205\n",
            "Epoch 997\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 3.6415e-04\n",
            "Train Loss: 0.00036414703936316073\n",
            "Epoch 998\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 3.6031e-04\n",
            "Train Loss: 0.0003603129298426211\n",
            "Epoch 999\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 3.6092e-04\n",
            "Train Loss: 0.00036091951187700033\n",
            "Saved\n",
            "Means:  [-0.05515616  0.04956003 -0.08232004  0.03485844  0.03585216 -0.03818864]\n",
            "Evals:  [3.60935261 3.17261737 3.03206496 2.98397468 2.90166679 2.78721146]\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jrr2MU1TOEen",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}