{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "composer_python27.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatteoTadiello/ProjectDeepLearning/blob/master/composer_python27.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "HewwFQYhMHcT",
        "outputId": "38616949-7ac9-4c28-c320-502ee62aa4d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "HOMEBASE = \"gdrive/My\\ Drive/Colab\\ Notebooks/Composer\"\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pw1paKpIKngt",
        "colab_type": "code",
        "outputId": "ea5861e4-8f6c-492a-cec1-4bff0ef85cae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "!ls gdrive/My\\ Drive/Colab\\ Notebooks/Composer\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu.theanorc  load_songs.py  Music\t\t README.md    train5.py\n",
            "gpu.theanorc  midi.py\t     NeuralComposer.zip  samples.npy  train.py\n",
            "lengths.npy   midi.pyc\t     Out\t\t train2.py    util.py\n",
            "live_edit.py  mt.py\t     rand.npy\t\t train3.py    util.pyc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qu-6Pw7ZPQfy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! python2.7 gdrive/My\\ Drive/Colab\\ Notebooks/Composer/mt.py gdrive/My\\ Drive/Colab\\ Notebooks/Composer/Out/out.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jrr2MU1TOEen",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ]
    },
    {
      "metadata": {
        "id": "tkuQVgaeLmTK",
        "colab_type": "code",
        "outputId": "30132a44-365b-42e6-8d09-13bbdd48ae32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 20769
        }
      },
      "cell_type": "code",
      "source": [
        "#Come mai è lento?\n",
        "! THEANO_FLAGS=blas.ldflags=\"-L/usr/lib/x86_64-linux-gnu/atlas/ -lblas\" python2.7 gdrive/My\\ Drive/Colab\\ Notebooks/Composer/train4.py gdrive/My\\ Drive/Colab\\ Notebooks/Composer/\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Keras...\n",
            "Theano Version: 1.0.4\n",
            "Using Theano backend.\n",
            "Keras Version: 2.2.4\n",
            "Loading Data...\n",
            "Loaded 4092 samples from 186 songs.\n",
            "4092\n",
            "Padding Songs...\n",
            "Building Model...\n",
            "(None, 16, 96, 96)\n",
            "(None, 16, 9216)\n",
            "(None, 16, 2000)\n",
            "(None, 16, 200)\n",
            "(None, 3200)\n",
            "(None, 1600)\n",
            "(None, 120)\n",
            "(None, 1600)\n",
            "(None, 3200)\n",
            "(None, 16, 200)\n",
            "(None, 16, 2000)\n",
            "(None, 16, 9216)\n",
            "(None, 16, 96, 96)\n",
            "Compiling SubModels...\n",
            "Training...\n",
            "Epoch 0\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 49s 264ms/step - loss: 0.7187\n",
            "Train Loss: 0.718744695186615\n",
            "Saved\n",
            "Means:  [ 0.12670767 -0.25823873  0.05277751 -0.13883188 -0.2588019  -0.04096937]\n",
            "Evals:  [1.11507495 0.40948673 0.2864814  0.253265   0.23918162 0.2258197 ]\n",
            "Epoch 1\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 257ms/step - loss: 0.1765\n",
            "Train Loss: 0.17648477852344513\n",
            "Epoch 2\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 256ms/step - loss: 0.0644\n",
            "Train Loss: 0.06440339237451553\n",
            "Epoch 3\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 252ms/step - loss: 0.0762\n",
            "Train Loss: 0.0761847048997879\n",
            "Epoch 4\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 49s 263ms/step - loss: 0.0394\n",
            "Train Loss: 0.03935517370700836\n",
            "Epoch 5\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 252ms/step - loss: 0.0281\n",
            "Train Loss: 0.028081955388188362\n",
            "Epoch 6\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 257ms/step - loss: 0.0227\n",
            "Train Loss: 0.022722361609339714\n",
            "Epoch 7\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 255ms/step - loss: 0.0197\n",
            "Train Loss: 0.019745640456676483\n",
            "Epoch 8\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 251ms/step - loss: 0.0179\n",
            "Train Loss: 0.017853928729891777\n",
            "Epoch 9\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 255ms/step - loss: 0.0164\n",
            "Train Loss: 0.016379527747631073\n",
            "Saved\n",
            "Means:  [ 0.5167479  -0.88300365 -0.7075431   0.7150613  -0.15390402 -0.16613974]\n",
            "Evals:  [7.1582777  1.99841538 1.17285999 1.06826815 0.87301292 0.55901056]\n",
            "Epoch 10\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 260ms/step - loss: 0.0152\n",
            "Train Loss: 0.015154274180531502\n",
            "Epoch 11\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 250ms/step - loss: 0.0142\n",
            "Train Loss: 0.014167864806950092\n",
            "Epoch 12\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 259ms/step - loss: 0.0134\n",
            "Train Loss: 0.01337516400963068\n",
            "Epoch 13\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 249ms/step - loss: 0.0127\n",
            "Train Loss: 0.012694048695266247\n",
            "Epoch 14\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 255ms/step - loss: 0.0121\n",
            "Train Loss: 0.012098900973796844\n",
            "Epoch 15\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 252ms/step - loss: 0.0116\n",
            "Train Loss: 0.011628313921391964\n",
            "Epoch 16\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 259ms/step - loss: 0.0112\n",
            "Train Loss: 0.011152032762765884\n",
            "Epoch 17\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 257ms/step - loss: 0.0108\n",
            "Train Loss: 0.010755595751106739\n",
            "Epoch 18\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 255ms/step - loss: 0.0105\n",
            "Train Loss: 0.010463343001902103\n",
            "Epoch 19\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 256ms/step - loss: 0.0102\n",
            "Train Loss: 0.01016982551664114\n",
            "Saved\n",
            "Means:  [ 0.30902347 -0.38247517 -0.25533625  0.26088706 -0.06374697 -0.19660464]\n",
            "Evals:  [8.19495021 2.67485532 1.58247269 1.37290981 1.1630968  0.72385765]\n",
            "Epoch 20\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 258ms/step - loss: 0.0099\n",
            "Train Loss: 0.009898166172206402\n",
            "Epoch 21\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 250ms/step - loss: 0.0097\n",
            "Train Loss: 0.009654093533754349\n",
            "Epoch 22\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 49s 261ms/step - loss: 0.0095\n",
            "Train Loss: 0.009466327726840973\n",
            "Epoch 23\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0093\n",
            "Train Loss: 0.009304621256887913\n",
            "Epoch 24\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 255ms/step - loss: 0.0091\n",
            "Train Loss: 0.009134684689342976\n",
            "Epoch 25\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0090\n",
            "Train Loss: 0.008971651084721088\n",
            "Epoch 26\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 247ms/step - loss: 0.0088\n",
            "Train Loss: 0.008783947676420212\n",
            "Epoch 27\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 255ms/step - loss: 0.0087\n",
            "Train Loss: 0.008670590817928314\n",
            "Epoch 28\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 248ms/step - loss: 0.0085\n",
            "Train Loss: 0.00852339155972004\n",
            "Epoch 29\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 260ms/step - loss: 0.0084\n",
            "Train Loss: 0.008399664424359798\n",
            "Saved\n",
            "Means:  [ 0.24263915 -0.18953744 -0.13952483  0.15773807 -0.17914623 -0.00593914]\n",
            "Evals:  [8.94510233 3.35417101 1.89819642 1.59637009 1.36588044 0.86724369]\n",
            "Epoch 30\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 259ms/step - loss: 0.0083\n",
            "Train Loss: 0.00829866249114275\n",
            "Epoch 31\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 248ms/step - loss: 0.0082\n",
            "Train Loss: 0.008212005719542503\n",
            "Epoch 32\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0081\n",
            "Train Loss: 0.008149100467562675\n",
            "Epoch 33\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 252ms/step - loss: 0.0081\n",
            "Train Loss: 0.00806752685457468\n",
            "Epoch 34\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 249ms/step - loss: 0.0080\n",
            "Train Loss: 0.007992690429091454\n",
            "Epoch 35\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 257ms/step - loss: 0.0079\n",
            "Train Loss: 0.007893201895058155\n",
            "Epoch 36\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 248ms/step - loss: 0.0079\n",
            "Train Loss: 0.0078583350405097\n",
            "Epoch 37\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 257ms/step - loss: 0.0078\n",
            "Train Loss: 0.007781799882650375\n",
            "Epoch 38\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 252ms/step - loss: 0.0077\n",
            "Train Loss: 0.007713266648352146\n",
            "Epoch 39\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 251ms/step - loss: 0.0076\n",
            "Train Loss: 0.0076422602869570255\n",
            "Saved\n",
            "Means:  [ 0.0358108  -0.07524758  0.00605129 -0.05095678 -0.4484034   0.20322183]\n",
            "Evals:  [9.1403964  3.7685063  2.13588353 1.68185113 1.50585842 0.89794597]\n",
            "Epoch 40\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0076\n",
            "Train Loss: 0.007593053858727217\n",
            "Epoch 41\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 260ms/step - loss: 0.0076\n",
            "Train Loss: 0.007568541448563337\n",
            "Epoch 42\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 250ms/step - loss: 0.0076\n",
            "Train Loss: 0.007567788939923048\n",
            "Epoch 43\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 259ms/step - loss: 0.0075\n",
            "Train Loss: 0.007515891455113888\n",
            "Epoch 44\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 251ms/step - loss: 0.0075\n",
            "Train Loss: 0.007483289577066898\n",
            "Epoch 45\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 256ms/step - loss: 0.0075\n",
            "Train Loss: 0.007462050300091505\n",
            "Epoch 46\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0074\n",
            "Train Loss: 0.007418341003358364\n",
            "Epoch 47\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0074\n",
            "Train Loss: 0.0073797921650111675\n",
            "Epoch 48\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 49s 262ms/step - loss: 0.0073\n",
            "Train Loss: 0.007301222067326307\n",
            "Epoch 49\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0073\n",
            "Train Loss: 0.007280483841896057\n",
            "Saved\n",
            "Means:  [ 0.01936733  0.02609435  0.09221354 -0.07561769 -0.768346    0.39222106]\n",
            "Evals:  [9.1778197  4.03064712 2.27064134 1.80158971 1.55997404 0.89753888]\n",
            "Epoch 50\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0072\n",
            "Train Loss: 0.007242278195917606\n",
            "Epoch 51\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 255ms/step - loss: 0.0072\n",
            "Train Loss: 0.00723961042240262\n",
            "Epoch 52\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 249ms/step - loss: 0.0072\n",
            "Train Loss: 0.0071797799319028854\n",
            "Epoch 53\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 255ms/step - loss: 0.0072\n",
            "Train Loss: 0.0071565224789083\n",
            "Epoch 54\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 256ms/step - loss: 0.0071\n",
            "Train Loss: 0.007112516090273857\n",
            "Epoch 55\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 259ms/step - loss: 0.0071\n",
            "Train Loss: 0.00711553730070591\n",
            "Epoch 56\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0070\n",
            "Train Loss: 0.0070352437905967236\n",
            "Epoch 57\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 250ms/step - loss: 0.0070\n",
            "Train Loss: 0.00704522430896759\n",
            "Epoch 58\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 255ms/step - loss: 0.0070\n",
            "Train Loss: 0.00697151618078351\n",
            "Epoch 59\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 249ms/step - loss: 0.0070\n",
            "Train Loss: 0.00697980634868145\n",
            "Saved\n",
            "Means:  [-0.03660524  0.191584    0.37258548 -0.2798065  -0.2650252   0.47732687]\n",
            "Evals:  [9.27787913 4.14645897 2.43888983 2.0299087  1.53998408 0.93269381]\n",
            "Epoch 60\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 256ms/step - loss: 0.0069\n",
            "Train Loss: 0.006927827838808298\n",
            "Epoch 61\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 256ms/step - loss: 0.0069\n",
            "Train Loss: 0.0069356560707092285\n",
            "Epoch 62\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 250ms/step - loss: 0.0069\n",
            "Train Loss: 0.006885346490889788\n",
            "Epoch 63\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0069\n",
            "Train Loss: 0.006914213299751282\n",
            "Epoch 64\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0068\n",
            "Train Loss: 0.0068273600190877914\n",
            "Epoch 65\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 248ms/step - loss: 0.0068\n",
            "Train Loss: 0.006789062172174454\n",
            "Epoch 66\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 258ms/step - loss: 0.0067\n",
            "Train Loss: 0.006718930322676897\n",
            "Epoch 67\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 251ms/step - loss: 0.0067\n",
            "Train Loss: 0.006718865595757961\n",
            "Epoch 68\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 257ms/step - loss: 0.0067\n",
            "Train Loss: 0.006652398966252804\n",
            "Epoch 69\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 250ms/step - loss: 0.0066\n",
            "Train Loss: 0.006637861020863056\n",
            "Saved\n",
            "Means:  [ 0.16147943 -0.12399878  0.28337613 -0.14710769  0.39867648 -0.52095765]\n",
            "Evals:  [9.36610603 4.87520269 2.98941529 2.30664493 1.58288377 0.91690613]\n",
            "Epoch 70\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 250ms/step - loss: 0.0066\n",
            "Train Loss: 0.006579305045306683\n",
            "Epoch 71\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 255ms/step - loss: 0.0066\n",
            "Train Loss: 0.006601734086871147\n",
            "Epoch 72\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 256ms/step - loss: 0.0066\n",
            "Train Loss: 0.006561754737049341\n",
            "Epoch 73\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0066\n",
            "Train Loss: 0.006558835972100496\n",
            "Epoch 74\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 255ms/step - loss: 0.0065\n",
            "Train Loss: 0.006487371399998665\n",
            "Epoch 75\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 249ms/step - loss: 0.0065\n",
            "Train Loss: 0.006482233293354511\n",
            "Epoch 76\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 255ms/step - loss: 0.0064\n",
            "Train Loss: 0.006391164846718311\n",
            "Epoch 77\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 252ms/step - loss: 0.0064\n",
            "Train Loss: 0.006413706112653017\n",
            "Epoch 78\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0062\n",
            "Train Loss: 0.006233796011656523\n",
            "Epoch 79\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 49s 261ms/step - loss: 0.0063\n",
            "Train Loss: 0.006265395320951939\n",
            "Saved\n",
            "Means:  [-0.6084409   0.13821468  0.45539474 -0.14981653  0.12162612 -0.594799  ]\n",
            "Evals:  [9.12159535 5.18960497 4.36290653 2.69618822 1.65480761 1.26124182]\n",
            "Epoch 80\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 255ms/step - loss: 0.0062\n",
            "Train Loss: 0.0062261768616735935\n",
            "Epoch 81\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 251ms/step - loss: 0.0064\n",
            "Train Loss: 0.006392888259142637\n",
            "Epoch 82\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 258ms/step - loss: 0.0061\n",
            "Train Loss: 0.006139013916254044\n",
            "Epoch 83\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 250ms/step - loss: 0.0060\n",
            "Train Loss: 0.006045736838132143\n",
            "Epoch 84\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 256ms/step - loss: 0.0060\n",
            "Train Loss: 0.00600276468321681\n",
            "Epoch 85\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 49s 262ms/step - loss: 0.0060\n",
            "Train Loss: 0.0060132634826004505\n",
            "Epoch 86\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0060\n",
            "Train Loss: 0.005977887660264969\n",
            "Epoch 87\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 256ms/step - loss: 0.0059\n",
            "Train Loss: 0.005945159122347832\n",
            "Epoch 88\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 249ms/step - loss: 0.0058\n",
            "Train Loss: 0.005817791447043419\n",
            "Epoch 89\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0058\n",
            "Train Loss: 0.005777361802756786\n",
            "Saved\n",
            "Means:  [ 0.4696604  -0.3476745  -0.17669667 -0.24523784 -0.46237522  0.4635271 ]\n",
            "Evals:  [9.12388674 4.80404906 4.59604143 3.48768635 2.35149917 1.65043849]\n",
            "Epoch 90\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 257ms/step - loss: 0.0057\n",
            "Train Loss: 0.005696468520909548\n",
            "Epoch 91\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 256ms/step - loss: 0.0057\n",
            "Train Loss: 0.005684357136487961\n",
            "Epoch 92\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0056\n",
            "Train Loss: 0.005616648122668266\n",
            "Epoch 93\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 250ms/step - loss: 0.0056\n",
            "Train Loss: 0.005641758907586336\n",
            "Epoch 94\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 245ms/step - loss: 0.0056\n",
            "Train Loss: 0.005575471557676792\n",
            "Epoch 95\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 257ms/step - loss: 0.0056\n",
            "Train Loss: 0.005584909114986658\n",
            "Epoch 96\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 256ms/step - loss: 0.0057\n",
            "Train Loss: 0.0056970445439219475\n",
            "Epoch 97\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 260ms/step - loss: 0.0057\n",
            "Train Loss: 0.005668344907462597\n",
            "Epoch 98\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 49s 261ms/step - loss: 0.0056\n",
            "Train Loss: 0.005551208276301622\n",
            "Epoch 99\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 250ms/step - loss: 0.0054\n",
            "Train Loss: 0.005407978780567646\n",
            "Saved\n",
            "Means:  [ 0.45081145 -0.00278249 -0.08036075 -0.8201252  -0.43699142  0.09030025]\n",
            "Evals:  [8.49260641 5.0957174  4.74002608 3.94176253 3.13400736 2.07595228]\n",
            "Epoch 100\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0053\n",
            "Train Loss: 0.005342167802155018\n",
            "Epoch 101\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0054\n",
            "Train Loss: 0.0054485914297401905\n",
            "Epoch 102\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 250ms/step - loss: 0.0056\n",
            "Train Loss: 0.005601831711828709\n",
            "Epoch 103\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 259ms/step - loss: 0.0055\n",
            "Train Loss: 0.005502915941178799\n",
            "Epoch 104\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 257ms/step - loss: 0.0052\n",
            "Train Loss: 0.005228276364505291\n",
            "Epoch 105\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 257ms/step - loss: 0.0051\n",
            "Train Loss: 0.0051102708093822\n",
            "Epoch 106\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 255ms/step - loss: 0.0050\n",
            "Train Loss: 0.005012014415115118\n",
            "Epoch 107\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 252ms/step - loss: 0.0050\n",
            "Train Loss: 0.004997706040740013\n",
            "Epoch 108\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 256ms/step - loss: 0.0050\n",
            "Train Loss: 0.0050452034920454025\n",
            "Epoch 109\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0052\n",
            "Train Loss: 0.005158425308763981\n",
            "Epoch 110\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 49s 265ms/step - loss: 0.0050\n",
            "Train Loss: 0.005034623667597771\n",
            "Epoch 111\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 256ms/step - loss: 0.0049\n",
            "Train Loss: 0.004938825033605099\n",
            "Epoch 112\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 251ms/step - loss: 0.0048\n",
            "Train Loss: 0.004826331976801157\n",
            "Epoch 113\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 257ms/step - loss: 0.0049\n",
            "Train Loss: 0.004856312647461891\n",
            "Epoch 114\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 251ms/step - loss: 0.0049\n",
            "Train Loss: 0.004903802648186684\n",
            "Epoch 115\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 258ms/step - loss: 0.0051\n",
            "Train Loss: 0.005079793743789196\n",
            "Epoch 116\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0051\n",
            "Train Loss: 0.005076786037534475\n",
            "Epoch 117\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0049\n",
            "Train Loss: 0.004921007435768843\n",
            "Epoch 118\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0046\n",
            "Train Loss: 0.004645338747650385\n",
            "Epoch 119\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 248ms/step - loss: 0.0046\n",
            "Train Loss: 0.004601086489856243\n",
            "Saved\n",
            "Means:  [-0.03986818 -0.13749109 -0.04011476 -0.27716675 -0.17721346 -0.09229748]\n",
            "Evals:  [8.13963967 5.52365357 4.95078582 4.29712411 3.4751087  2.85739703]\n",
            "Epoch 120\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 249ms/step - loss: 0.0045\n",
            "Train Loss: 0.004541757516562939\n",
            "Epoch 121\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 256ms/step - loss: 0.0046\n",
            "Train Loss: 0.004584767390042543\n",
            "Epoch 122\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0047\n",
            "Train Loss: 0.004657280631363392\n",
            "Epoch 123\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 257ms/step - loss: 0.0048\n",
            "Train Loss: 0.004805963020771742\n",
            "Epoch 124\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0047\n",
            "Train Loss: 0.004736029077321291\n",
            "Epoch 125\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 249ms/step - loss: 0.0046\n",
            "Train Loss: 0.004592670127749443\n",
            "Epoch 126\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0045\n",
            "Train Loss: 0.004486181773245335\n",
            "Epoch 127\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 246ms/step - loss: 0.0044\n",
            "Train Loss: 0.00442111911252141\n",
            "Epoch 128\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0044\n",
            "Train Loss: 0.004368161782622337\n",
            "Epoch 129\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 258ms/step - loss: 0.0044\n",
            "Train Loss: 0.004364039283245802\n",
            "Epoch 130\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 252ms/step - loss: 0.0044\n",
            "Train Loss: 0.004424569196999073\n",
            "Epoch 131\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 256ms/step - loss: 0.0045\n",
            "Train Loss: 0.004522995557636023\n",
            "Epoch 132\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 247ms/step - loss: 0.0046\n",
            "Train Loss: 0.004593302495777607\n",
            "Epoch 133\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 256ms/step - loss: 0.0045\n",
            "Train Loss: 0.004523911979049444\n",
            "Epoch 134\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 249ms/step - loss: 0.0044\n",
            "Train Loss: 0.004415666684508324\n",
            "Epoch 135\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 258ms/step - loss: 0.0043\n",
            "Train Loss: 0.004287494346499443\n",
            "Epoch 136\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 260ms/step - loss: 0.0042\n",
            "Train Loss: 0.0042468709871172905\n",
            "Epoch 137\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 248ms/step - loss: 0.0042\n",
            "Train Loss: 0.004240819253027439\n",
            "Epoch 138\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0043\n",
            "Train Loss: 0.004319560248404741\n",
            "Epoch 139\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 249ms/step - loss: 0.0044\n",
            "Train Loss: 0.004395229276269674\n",
            "Saved\n",
            "Means:  [ 0.3657948  -0.15398985  0.3847799  -0.12944365 -0.08859643  0.02560758]\n",
            "Evals:  [7.33881302 5.02843867 4.6165768  4.21569675 3.63190215 2.99805051]\n",
            "Epoch 140\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 251ms/step - loss: 0.0043\n",
            "Train Loss: 0.0043430025689303875\n",
            "Epoch 141\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 260ms/step - loss: 0.0042\n",
            "Train Loss: 0.0042451610788702965\n",
            "Epoch 142\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 258ms/step - loss: 0.0042\n",
            "Train Loss: 0.0042013851925730705\n",
            "Epoch 143\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 252ms/step - loss: 0.0043\n",
            "Train Loss: 0.0042558698914945126\n",
            "Epoch 144\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0043\n",
            "Train Loss: 0.004345661029219627\n",
            "Epoch 145\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 249ms/step - loss: 0.0043\n",
            "Train Loss: 0.0042994036339223385\n",
            "Epoch 146\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 255ms/step - loss: 0.0042\n",
            "Train Loss: 0.004185557831078768\n",
            "Epoch 147\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 249ms/step - loss: 0.0041\n",
            "Train Loss: 0.004104345105588436\n",
            "Epoch 148\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 49s 263ms/step - loss: 0.0041\n",
            "Train Loss: 0.004075648263096809\n",
            "Epoch 149\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0041\n",
            "Train Loss: 0.004066427703946829\n",
            "Epoch 150\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 249ms/step - loss: 0.0040\n",
            "Train Loss: 0.004024583380669355\n",
            "Epoch 151\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 256ms/step - loss: 0.0040\n",
            "Train Loss: 0.004013539291918278\n",
            "Epoch 152\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 249ms/step - loss: 0.0040\n",
            "Train Loss: 0.0040349820628762245\n",
            "Epoch 153\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 256ms/step - loss: 0.0040\n",
            "Train Loss: 0.004037974402308464\n",
            "Epoch 154\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 258ms/step - loss: 0.0040\n",
            "Train Loss: 0.003998162690550089\n",
            "Epoch 155\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 256ms/step - loss: 0.0039\n",
            "Train Loss: 0.003925820346921682\n",
            "Epoch 156\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 256ms/step - loss: 0.0039\n",
            "Train Loss: 0.0038543115369975567\n",
            "Epoch 157\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 250ms/step - loss: 0.0038\n",
            "Train Loss: 0.003806159133091569\n",
            "Epoch 158\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 257ms/step - loss: 0.0038\n",
            "Train Loss: 0.0037946642842143774\n",
            "Epoch 159\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0038\n",
            "Train Loss: 0.003814169205725193\n",
            "Saved\n",
            "Means:  [-0.11557279 -0.07575572 -0.2928913  -0.29687116 -0.15315448 -0.14581229]\n",
            "Evals:  [6.77352751 4.32675692 4.15315262 4.11523879 3.60866138 3.35859382]\n",
            "Epoch 160\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 250ms/step - loss: 0.0039\n",
            "Train Loss: 0.003884483128786087\n",
            "Epoch 161\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0039\n",
            "Train Loss: 0.003930747043341398\n",
            "Epoch 162\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 251ms/step - loss: 0.0039\n",
            "Train Loss: 0.0038946447893977165\n",
            "Epoch 163\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 247ms/step - loss: 0.0038\n",
            "Train Loss: 0.0038079763762652874\n",
            "Epoch 164\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 255ms/step - loss: 0.0037\n",
            "Train Loss: 0.0037106333766132593\n",
            "Epoch 165\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 249ms/step - loss: 0.0037\n",
            "Train Loss: 0.003683660412207246\n",
            "Epoch 166\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0037\n",
            "Train Loss: 0.0037112124264240265\n",
            "Epoch 167\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 260ms/step - loss: 0.0037\n",
            "Train Loss: 0.003729049349203706\n",
            "Epoch 168\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 251ms/step - loss: 0.0037\n",
            "Train Loss: 0.0037118697073310614\n",
            "Epoch 169\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0037\n",
            "Train Loss: 0.00368105317465961\n",
            "Epoch 170\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 250ms/step - loss: 0.0036\n",
            "Train Loss: 0.0036461292766034603\n",
            "Epoch 171\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0036\n",
            "Train Loss: 0.003645253134891391\n",
            "Epoch 172\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 248ms/step - loss: 0.0037\n",
            "Train Loss: 0.003672002349048853\n",
            "Epoch 173\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 257ms/step - loss: 0.0037\n",
            "Train Loss: 0.003672980237752199\n",
            "Epoch 174\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 258ms/step - loss: 0.0037\n",
            "Train Loss: 0.0036561081651598215\n",
            "Epoch 175\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 248ms/step - loss: 0.0036\n",
            "Train Loss: 0.0036144705954939127\n",
            "Epoch 176\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 257ms/step - loss: 0.0036\n",
            "Train Loss: 0.003557638032361865\n",
            "Epoch 177\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 247ms/step - loss: 0.0036\n",
            "Train Loss: 0.0035673610400408506\n",
            "Epoch 178\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0036\n",
            "Train Loss: 0.003559845732524991\n",
            "Epoch 179\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 251ms/step - loss: 0.0036\n",
            "Train Loss: 0.0035642965231090784\n",
            "Saved\n",
            "Means:  [ 0.1356255  -0.03979116  0.04273371  0.18671058 -0.0183131  -0.285509  ]\n",
            "Evals:  [6.7936773  4.12195342 3.99097047 3.88884184 3.70607333 3.32309072]\n",
            "Epoch 180\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 256ms/step - loss: 0.0036\n",
            "Train Loss: 0.0035787334199994802\n",
            "Epoch 181\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0035\n",
            "Train Loss: 0.003537719836458564\n",
            "Epoch 182\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 252ms/step - loss: 0.0035\n",
            "Train Loss: 0.0034794039092957973\n",
            "Epoch 183\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 45s 245ms/step - loss: 0.0034\n",
            "Train Loss: 0.0034385777544230223\n",
            "Epoch 184\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 252ms/step - loss: 0.0034\n",
            "Train Loss: 0.003421865403652191\n",
            "Epoch 185\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 248ms/step - loss: 0.0034\n",
            "Train Loss: 0.0034088424872606993\n",
            "Epoch 186\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 256ms/step - loss: 0.0034\n",
            "Train Loss: 0.0034463100600987673\n",
            "Epoch 187\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 252ms/step - loss: 0.0035\n",
            "Train Loss: 0.0034827147610485554\n",
            "Epoch 188\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 247ms/step - loss: 0.0035\n",
            "Train Loss: 0.003489902475848794\n",
            "Epoch 189\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0035\n",
            "Train Loss: 0.003461848245933652\n",
            "Epoch 190\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 247ms/step - loss: 0.0034\n",
            "Train Loss: 0.003401788417249918\n",
            "Epoch 191\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0033\n",
            "Train Loss: 0.0033486501779407263\n",
            "Epoch 192\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0033\n",
            "Train Loss: 0.003319572424516082\n",
            "Epoch 193\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 49s 263ms/step - loss: 0.0033\n",
            "Train Loss: 0.003307395614683628\n",
            "Epoch 194\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0033\n",
            "Train Loss: 0.0033212474081665277\n",
            "Epoch 195\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 248ms/step - loss: 0.0033\n",
            "Train Loss: 0.0033297657500952482\n",
            "Epoch 196\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 255ms/step - loss: 0.0033\n",
            "Train Loss: 0.003299441421404481\n",
            "Epoch 197\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 249ms/step - loss: 0.0033\n",
            "Train Loss: 0.003277061739936471\n",
            "Epoch 198\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 257ms/step - loss: 0.0033\n",
            "Train Loss: 0.0032525029964745045\n",
            "Epoch 199\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 257ms/step - loss: 0.0033\n",
            "Train Loss: 0.00325664971023798\n",
            "Saved\n",
            "Means:  [ 0.04724482 -0.0482654  -0.08114725  0.04062067 -0.06404879 -0.23346919]\n",
            "Evals:  [6.29645105 4.11182891 4.06764353 3.83715982 3.5557386  3.30897318]\n",
            "Epoch 200\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 252ms/step - loss: 0.0032\n",
            "Train Loss: 0.0032480775844305754\n",
            "Epoch 201\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 250ms/step - loss: 0.0032\n",
            "Train Loss: 0.0032425487879663706\n",
            "Epoch 202\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0032\n",
            "Train Loss: 0.0032048781868070364\n",
            "Epoch 203\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 248ms/step - loss: 0.0032\n",
            "Train Loss: 0.003179724793881178\n",
            "Epoch 204\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 260ms/step - loss: 0.0032\n",
            "Train Loss: 0.0031554449815303087\n",
            "Epoch 205\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 252ms/step - loss: 0.0032\n",
            "Train Loss: 0.0031769045162945986\n",
            "Epoch 206\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0032\n",
            "Train Loss: 0.0031737491954118013\n",
            "Epoch 207\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0032\n",
            "Train Loss: 0.003191498341038823\n",
            "Epoch 208\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 248ms/step - loss: 0.0032\n",
            "Train Loss: 0.0032030139118433\n",
            "Epoch 209\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 255ms/step - loss: 0.0032\n",
            "Train Loss: 0.0031990138813853264\n",
            "Epoch 210\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 249ms/step - loss: 0.0032\n",
            "Train Loss: 0.0031716013327240944\n",
            "Epoch 211\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0031\n",
            "Train Loss: 0.0031032783444970846\n",
            "Epoch 212\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 260ms/step - loss: 0.0030\n",
            "Train Loss: 0.003044827375560999\n",
            "Epoch 213\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 247ms/step - loss: 0.0030\n",
            "Train Loss: 0.0030204460490494967\n",
            "Epoch 214\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 255ms/step - loss: 0.0030\n",
            "Train Loss: 0.003019706578925252\n",
            "Epoch 215\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 249ms/step - loss: 0.0031\n",
            "Train Loss: 0.003052283311262727\n",
            "Epoch 216\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 257ms/step - loss: 0.0031\n",
            "Train Loss: 0.0030736576300114393\n",
            "Epoch 217\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0031\n",
            "Train Loss: 0.0031106453388929367\n",
            "Epoch 218\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0031\n",
            "Train Loss: 0.0031306983437389135\n",
            "Epoch 219\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 260ms/step - loss: 0.0031\n",
            "Train Loss: 0.0031283264979720116\n",
            "Epoch 220\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 249ms/step - loss: 0.0031\n",
            "Train Loss: 0.0031066052615642548\n",
            "Epoch 221\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 255ms/step - loss: 0.0031\n",
            "Train Loss: 0.0030603082850575447\n",
            "Epoch 222\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 251ms/step - loss: 0.0030\n",
            "Train Loss: 0.0030267462134361267\n",
            "Epoch 223\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 257ms/step - loss: 0.0030\n",
            "Train Loss: 0.0030132795218378305\n",
            "Epoch 224\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0030\n",
            "Train Loss: 0.0030081679578870535\n",
            "Epoch 225\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 256ms/step - loss: 0.0030\n",
            "Train Loss: 0.0030104792676866055\n",
            "Epoch 226\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 257ms/step - loss: 0.0030\n",
            "Train Loss: 0.002966848434880376\n",
            "Epoch 227\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 250ms/step - loss: 0.0029\n",
            "Train Loss: 0.0029106568545103073\n",
            "Epoch 228\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 255ms/step - loss: 0.0029\n",
            "Train Loss: 0.002880597021430731\n",
            "Epoch 229\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 251ms/step - loss: 0.0029\n",
            "Train Loss: 0.002882061991840601\n",
            "Epoch 230\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 252ms/step - loss: 0.0029\n",
            "Train Loss: 0.0028906718362122774\n",
            "Epoch 231\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0029\n",
            "Train Loss: 0.0028984725940972567\n",
            "Epoch 232\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 252ms/step - loss: 0.0029\n",
            "Train Loss: 0.0028954590670764446\n",
            "Epoch 233\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0029\n",
            "Train Loss: 0.0029134880751371384\n",
            "Epoch 234\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 247ms/step - loss: 0.0029\n",
            "Train Loss: 0.0029347711242735386\n",
            "Epoch 235\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 251ms/step - loss: 0.0029\n",
            "Train Loss: 0.002910593757405877\n",
            "Epoch 236\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0029\n",
            "Train Loss: 0.0028747995384037495\n",
            "Epoch 237\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 246ms/step - loss: 0.0028\n",
            "Train Loss: 0.0028326441533863544\n",
            "Epoch 238\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 259ms/step - loss: 0.0028\n",
            "Train Loss: 0.0028184191323816776\n",
            "Epoch 239\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 248ms/step - loss: 0.0028\n",
            "Train Loss: 0.0028160931542515755\n",
            "Epoch 240\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0028\n",
            "Train Loss: 0.0028419876471161842\n",
            "Epoch 241\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 250ms/step - loss: 0.0029\n",
            "Train Loss: 0.002881309948861599\n",
            "Epoch 242\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 248ms/step - loss: 0.0029\n",
            "Train Loss: 0.0028733720537275076\n",
            "Epoch 243\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 259ms/step - loss: 0.0029\n",
            "Train Loss: 0.002855238737538457\n",
            "Epoch 244\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 248ms/step - loss: 0.0028\n",
            "Train Loss: 0.0027950224466621876\n",
            "Epoch 245\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 258ms/step - loss: 0.0028\n",
            "Train Loss: 0.00277129327878356\n",
            "Epoch 246\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 249ms/step - loss: 0.0027\n",
            "Train Loss: 0.002746204612776637\n",
            "Epoch 247\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0028\n",
            "Train Loss: 0.002756952540948987\n",
            "Epoch 248\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0028\n",
            "Train Loss: 0.0027793620247393847\n",
            "Epoch 249\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 251ms/step - loss: 0.0028\n",
            "Train Loss: 0.002835382940247655\n",
            "Saved\n",
            "Means:  [ 0.01042282 -0.05265069  0.16686907 -0.0569664   0.00297074 -0.01502324]\n",
            "Evals:  [5.74362633 3.95971974 3.90841584 3.71297633 3.47791453 3.44009569]\n",
            "Epoch 250\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 248ms/step - loss: 0.0028\n",
            "Train Loss: 0.0028456440195441246\n",
            "Epoch 251\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 49s 262ms/step - loss: 0.0028\n",
            "Train Loss: 0.0028409347869455814\n",
            "Epoch 252\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 247ms/step - loss: 0.0028\n",
            "Train Loss: 0.0027785806450992823\n",
            "Epoch 253\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 252ms/step - loss: 0.0027\n",
            "Train Loss: 0.0027161170728504658\n",
            "Epoch 254\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 251ms/step - loss: 0.0027\n",
            "Train Loss: 0.0026733148843050003\n",
            "Epoch 255\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 252ms/step - loss: 0.0027\n",
            "Train Loss: 0.002685756888240576\n",
            "Epoch 256\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0027\n",
            "Train Loss: 0.002677746582776308\n",
            "Epoch 257\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 256ms/step - loss: 0.0027\n",
            "Train Loss: 0.002689175773411989\n",
            "Epoch 258\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 257ms/step - loss: 0.0027\n",
            "Train Loss: 0.0026721619069576263\n",
            "Epoch 259\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 249ms/step - loss: 0.0027\n",
            "Train Loss: 0.002677609445527196\n",
            "Epoch 260\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0027\n",
            "Train Loss: 0.0026624836027622223\n",
            "Epoch 261\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0027\n",
            "Train Loss: 0.002667719265446067\n",
            "Epoch 262\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 252ms/step - loss: 0.0027\n",
            "Train Loss: 0.002655304968357086\n",
            "Epoch 263\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 257ms/step - loss: 0.0026\n",
            "Train Loss: 0.0026421791408210993\n",
            "Epoch 264\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 256ms/step - loss: 0.0026\n",
            "Train Loss: 0.0026232865639030933\n",
            "Epoch 265\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 255ms/step - loss: 0.0026\n",
            "Train Loss: 0.002638643840327859\n",
            "Epoch 266\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0026\n",
            "Train Loss: 0.002627566223964095\n",
            "Epoch 267\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 248ms/step - loss: 0.0026\n",
            "Train Loss: 0.0026313932612538338\n",
            "Epoch 268\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 256ms/step - loss: 0.0026\n",
            "Train Loss: 0.002636197954416275\n",
            "Epoch 269\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 248ms/step - loss: 0.0026\n",
            "Train Loss: 0.0026087164878845215\n",
            "Epoch 270\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0026\n",
            "Train Loss: 0.002606118330731988\n",
            "Epoch 271\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 256ms/step - loss: 0.0026\n",
            "Train Loss: 0.002599514089524746\n",
            "Epoch 272\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 248ms/step - loss: 0.0026\n",
            "Train Loss: 0.0025825374759733677\n",
            "Epoch 273\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0026\n",
            "Train Loss: 0.0025704577565193176\n",
            "Epoch 274\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 249ms/step - loss: 0.0026\n",
            "Train Loss: 0.002574934856966138\n",
            "Epoch 275\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 259ms/step - loss: 0.0026\n",
            "Train Loss: 0.002559580374509096\n",
            "Epoch 276\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 250ms/step - loss: 0.0026\n",
            "Train Loss: 0.002553297206759453\n",
            "Epoch 277\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 49s 262ms/step - loss: 0.0025\n",
            "Train Loss: 0.0025296478997915983\n",
            "Epoch 278\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0025\n",
            "Train Loss: 0.002526547061279416\n",
            "Epoch 279\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 46s 249ms/step - loss: 0.0025\n",
            "Train Loss: 0.0025209684390574694\n",
            "Epoch 280\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 48s 257ms/step - loss: 0.0025\n",
            "Train Loss: 0.0025165074039250612\n",
            "Epoch 281\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0025\n",
            "Train Loss: 0.002504616742953658\n",
            "Epoch 282\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 254ms/step - loss: 0.0025\n",
            "Train Loss: 0.00248841755092144\n",
            "Epoch 283\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 253ms/step - loss: 0.0025\n",
            "Train Loss: 0.00248528434894979\n",
            "Epoch 284\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 255ms/step - loss: 0.0025\n",
            "Train Loss: 0.002474951557815075\n",
            "Epoch 285\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 47s 255ms/step - loss: 0.0025\n",
            "Train Loss: 0.002464144956320524\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2GhZsZceO7W_",
        "colab_type": "code",
        "outputId": "d5640ca1-d28e-4ab0-e5de-b809b736b1cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "!sudo apt-get install python-numpy python-scipy libblas-dev liblapack-dev"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libblas-dev is already the newest version (3.7.1-4ubuntu1).\n",
            "liblapack-dev is already the newest version (3.7.1-4ubuntu1).\n",
            "python-numpy is already the newest version (1:1.13.3-2ubuntu1).\n",
            "python-scipy is already the newest version (0.19.1-2ubuntu1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 6 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qmPrjtuWajfH",
        "colab_type": "code",
        "outputId": "2ca4999d-b55f-40f9-d315-bde4d4b0f0c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "!sudo apt install libblas-dev"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libblas-dev is already the newest version (3.7.1-4ubuntu1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 6 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vwsg0gK7d2LE",
        "colab_type": "code",
        "outputId": "728a76d2-6642-4022-b7d4-185624be6041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "!find /usr -name \"libblas.so\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/x86_64-linux-gnu/blas/libblas.so\n",
            "/usr/lib/x86_64-linux-gnu/atlas/libblas.so\n",
            "/usr/lib/x86_64-linux-gnu/openblas/libblas.so\n",
            "/usr/lib/x86_64-linux-gnu/libblas.so\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Lc6l8ursUW-E",
        "colab_type": "code",
        "outputId": "bb3f0709-897a-4ab3-d486-ae81f971d0ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        }
      },
      "cell_type": "code",
      "source": [
        "! python2.7 gdrive/My\\ Drive/Colab\\ Notebooks/Composer/train4.py gdrive/My\\ Drive/Colab\\ Notebooks/Composer/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Keras...\n",
            "Theano Version: 1.0.4\n",
            "Using Theano backend.\n",
            "Keras Version: 2.2.4\n",
            "Loading Data...\n",
            "Loaded 4092 samples from 186 songs.\n",
            "4092\n",
            "Padding Songs...\n",
            "Building Model...\n",
            "(None, 16, 96, 96)\n",
            "(None, 16, 9216)\n",
            "(None, 16, 2000)\n",
            "(None, 16, 200)\n",
            "(None, 3200)\n",
            "(None, 1600)\n",
            "(None, 120)\n",
            "(None, 1600)\n",
            "(None, 3200)\n",
            "(None, 16, 200)\n",
            "(None, 16, 2000)\n",
            "(None, 16, 9216)\n",
            "(None, 16, 96, 96)\n",
            "Compiling SubModels...\n",
            "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
            "Training...\n",
            "Epoch 0\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 83ms/step - loss: 0.7187\n",
            "Train Loss: 0.718744695186615\n",
            "Saved\n",
            "Means:  [ 0.12665945 -0.25854418  0.05265978 -0.13903767 -0.25854284 -0.04067894]\n",
            "Evals:  [1.11494973 0.40951338 0.28651215 0.25327379 0.23921141 0.22581126]\n",
            "Epoch 1\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 16s 87ms/step - loss: 0.1765\n",
            "Train Loss: 0.17647278308868408\n",
            "Epoch 2\n",
            "Epoch 1/1\n",
            "186/186 [==============================] - 15s 80ms/step - loss: 0.0645\n",
            "Train Loss: 0.0644644945859909\n",
            "Epoch 3\n",
            "Epoch 1/1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}